{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a SageMaker image-classifier microservice\n",
    "\n",
    "## Manually test the API and model function by sending a single dog image\n",
    "\n",
    "### Project for AICamp course: [Full Stack Deep Learning in AWS - Online](https://learn.xnextcon.com/course/courseDetails/C2031717)\n",
    "\n",
    "### John Burt    \n",
    "\n",
    "#### March 2020\n",
    "\n",
    "\n",
    "## The project\n",
    "For this project, the task was to create and train an image classifier using Amazon SageMaker, then deploy a classifier instance as a microservice via the AWS API Gateway. I chose to make a dog breed classifier using a set of images made available by Stanford University. \n",
    "\n",
    "### For more details, see my [project github site](https://github.com/johnmburt/projects/tree/master/AWS/sagemaker_dog_breed_id)\n",
    "\n",
    "\n",
    "## This notebook\n",
    "Test the trained model instance, via an AWS Gateway API call. This notebook lets you select a local image file, prepares the image data, passes it to the model for inference, then displayes results. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get class info from training lst file \n",
    "\n",
    "I'll use the directory name in the path to get dog breed name for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File dog_breeds_all_fold_1_train.lst does not exist: 'dog_breeds_all_fold_1_train.lst'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8d0df7bb4cc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrainlstfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'dog_breeds_all_fold_1_train.lst'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainlstfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sampid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'classid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'path'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m classnames = np.array([s.split('-')[1].split('/')[0] \n\u001b[0;32m      9\u001b[0m                        for s in df.groupby(by='classid').first().path])\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\datasci\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\datasci\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\datasci\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\datasci\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\datasci\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File dog_breeds_all_fold_1_train.lst does not exist: 'dog_breeds_all_fold_1_train.lst'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# lst file used for training\n",
    "trainlstfile = 'dog_breeds_all_fold_1_train.lst'\n",
    "\n",
    "df = pd.read_csv(trainlstfile, sep='\\t', names=['sampid','classid','path'])\n",
    "classnames = np.array([s.split('-')[1].split('/')[0] \n",
    "                       for s in df.groupby(by='classid').first().path])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filename selection dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "\n",
    "from PyQt5.QtWidgets import QFileDialog\n",
    "\n",
    "def gui_fname(dir=None, filters=None):\n",
    "    \"\"\"Select a file via a dialog and return the file name.\"\"\"\n",
    "    if dir is None: dir = './'\n",
    "    if filters is None: filters = 'All files (*.*)'\n",
    "    fname = QFileDialog.getOpenFileName(None, \"Select file...\", \n",
    "                dir, filter=filters)\n",
    "    return fname[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select dog image, classify breed\n",
    "\n",
    "- Use a file selection dialog to choose a dog image file in a local folder.\n",
    "\n",
    "- Format and embed image into json payload object.\n",
    "\n",
    "- Post to the image payload to the API gateway.\n",
    "\n",
    "- Receive model results and select breed ID based on highest output value.\n",
    "\n",
    "Note: I've modified the Lambda function to take multiple images in the form of a list. The API then returns a list of results. If I send a single image in the payload, the Lambda detects this and just does one classification, but still returns a list of results with one element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted dog breed, sorted by model output:\n",
      "\n",
      "ID\tOutput\tBreed name\n",
      "\n",
      "2   \t0.855 *\tMaltese_dog\n",
      "52   \t0.034  \tWest_Highland_white_terrier\n",
      "53   \t0.019  \tLhasa\n",
      "39   \t0.014  \tSealyham_terrier\n",
      "105   \t0.011  \tGreat_Pyrenees\n",
      "4   \t0.006  \tShih\n",
      "113   \t0.005  \ttoy_poodle\n",
      "71   \t0.004  \tkuvasz\n",
      "78   \t0.004  \tOld_English_sheepdog\n",
      "49   \t0.004  \tTibetan_terrier\n",
      "43   \t0.003  \tDandie_Dinmont\n",
      "65   \t0.003  \tclumber\n",
      "3   \t0.003  \tPekinese\n",
      "106   \t0.002  \tSamoyed\n",
      "114   \t0.002  \tminiature_poodle\n",
      "45   \t0.002  \tminiature_schnauzer\n",
      "1   \t0.002  \tJapanese_spaniel\n",
      "51   \t0.001  \tsoft\n",
      "36   \t0.001  \tYorkshire_terrier\n",
      "6   \t0.001  \tpapillon\n",
      "77   \t0.001  \tkomondor\n",
      "5   \t0.001  \tBlenheim_spaniel\n",
      "18   \t0.001  \tborzoi\n",
      "37   \t0.001  \twire\n",
      "61   \t0.001  \tEnglish_setter\n",
      "102   \t0.001  \tpug\n",
      "34   \t0.001  \tNorfolk_terrier\n",
      "96   \t0.001  \tSaint_Bernard\n",
      "57   \t0.001  \tLabrador_retriever\n",
      "28   \t0.001  \tStaffordshire_bullterrier\n",
      "107   \t0.001  \tPomeranian\n",
      "48   \t0.001  \tScotch_terrier\n",
      "64   \t0.001  \tBrittany_spaniel\n",
      "115   \t0.001  \tstandard_poodle\n",
      "7   \t0.001  \ttoy_terrier\n",
      "91   \t0.001  \tboxer\n",
      "68   \t0.000  \tcocker_spaniel\n",
      "38   \t0.000  \tLakeland_terrier\n",
      "94   \t0.000  \tFrench_bulldog\n",
      "95   \t0.000  \tGreat_Dane\n",
      "41   \t0.000  \tcairn\n",
      "11   \t0.000  \tbeagle\n",
      "0   \t0.000  \tChihuahua\n",
      "30   \t0.000  \tBedlington_terrier\n",
      "100   \t0.000  \taffenpinscher\n",
      "104   \t0.000  \tNewfoundland\n",
      "50   \t0.000  \tsilky_terrier\n",
      "67   \t0.000  \tWelsh_springer_spaniel\n",
      "16   \t0.000  \tEnglish_foxhound\n",
      "82   \t0.000  \tBouvier_des_Flandres\n",
      "81   \t0.000  \tBorder_collie\n",
      "29   \t0.000  \tAmerican_Staffordshire_terrier\n",
      "72   \t0.000  \tschipperke\n",
      "42   \t0.000  \tAustralian_terrier\n",
      "99   \t0.000  \tSiberian_husky\n",
      "98   \t0.000  \tmalamute\n",
      "32   \t0.000  \tKerry_blue_terrier\n",
      "25   \t0.000  \tSaluki\n",
      "44   \t0.000  \tBoston_bull\n",
      "46   \t0.000  \tgiant_schnauzer\n",
      "47   \t0.000  \tstandard_schnauzer\n",
      "92   \t0.000  \tbull_mastiff\n",
      "79   \t0.000  \tShetland_sheepdog\n",
      "56   \t0.000  \tgolden_retriever\n",
      "109   \t0.000  \tkeeshond\n",
      "23   \t0.000  \tNorwegian_elkhound\n",
      "69   \t0.000  \tSussex_spaniel\n",
      "112   \t0.000  \tCardigan\n",
      "86   \t0.000  \tminiature_pinscher\n",
      "59   \t0.000  \tGerman_short\n",
      "35   \t0.000  \tNorwich_terrier\n",
      "17   \t0.000  \tredbone\n",
      "55   \t0.000  \tcurly\n",
      "15   \t0.000  \tWalker_hound\n",
      "93   \t0.000  \tTibetan_mastiff\n",
      "31   \t0.000  \tBorder_terrier\n",
      "75   \t0.000  \tbriard\n",
      "110   \t0.000  \tBrabancon_griffon\n",
      "90   \t0.000  \tEntleBucher\n",
      "87   \t0.000  \tGreater_Swiss_Mountain_dog\n",
      "63   \t0.000  \tGordon_setter\n",
      "27   \t0.000  \tWeimaraner\n",
      "9   \t0.000  \tAfghan_hound\n",
      "14   \t0.000  \tblack\n",
      "24   \t0.000  \totterhound\n",
      "20   \t0.000  \tItalian_greyhound\n",
      "108   \t0.000  \tchow\n",
      "22   \t0.000  \tIbizan_hound\n",
      "85   \t0.000  \tDoberman\n",
      "13   \t0.000  \tbluetick\n",
      "10   \t0.000  \tbasset\n",
      "80   \t0.000  \tcollie\n",
      "83   \t0.000  \tRottweiler\n",
      "111   \t0.000  \tPembroke\n",
      "21   \t0.000  \twhippet\n",
      "116   \t0.000  \tMexican_hairless\n",
      "58   \t0.000  \tChesapeake_Bay_retriever\n",
      "66   \t0.000  \tEnglish_springer\n",
      "97   \t0.000  \tEskimo_dog\n",
      "88   \t0.000  \tBernese_mountain_dog\n",
      "89   \t0.000  \tAppenzeller\n",
      "70   \t0.000  \tIrish_water_spaniel\n",
      "101   \t0.000  \tbasenji\n",
      "118   \t0.000  \tdhole\n",
      "19   \t0.000  \tIrish_wolfhound\n",
      "33   \t0.000  \tIrish_terrier\n",
      "74   \t0.000  \tmalinois\n",
      "73   \t0.000  \tgroenendael\n",
      "8   \t0.000  \tRhodesian_ridgeback\n",
      "60   \t0.000  \tvizsla\n",
      "40   \t0.000  \tAiredale\n",
      "12   \t0.000  \tbloodhound\n",
      "84   \t0.000  \tGerman_shepherd\n",
      "76   \t0.000  \tkelpie\n",
      "26   \t0.000  \tScottish_deerhound\n",
      "119   \t0.000  \tAfrican_hunting_dog\n",
      "103   \t0.000  \tLeonberg\n",
      "54   \t0.000  \tflat\n",
      "117   \t0.000  \tdingo\n",
      "62   \t0.000  \tIrish_setter\n"
     ]
    }
   ],
   "source": [
    "import base64 # encode/decode image in base64\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Collection of dog images not in training set\n",
    "rootdir = 'C:/Users/john/notebooks/aicamp/dogs/test_images'\n",
    "\n",
    "# select an image file to test\n",
    "imgpath = gui_fname(dir=rootdir, filters='image (*.jpg)')\n",
    "\n",
    "# read the image, convert to base64, embed in json payload object\n",
    "with open(imgpath, 'rb') as image_file:\n",
    "   encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "payload = json.dumps( {'body': encoded_string } )\n",
    "\n",
    "# my breed prediction microservice API URL\n",
    "api_url = 'https://i0txv99f7j.execute-api.us-west-2.amazonaws.com/beta/predict'\n",
    "\n",
    "# post the image, receive inference response\n",
    "r = requests.post(url=api_url, data=payload, timeout=5)\n",
    "\n",
    "try:\n",
    "    # Classifier output is a list of results,\n",
    "    # Since I sent one image, it will be the first list element\n",
    "    classout = np.array(r.json()['body'])[0]\n",
    "\n",
    "    # select highest output \n",
    "    selclass = np.argmax(classout)\n",
    "    # sort by output, desc\n",
    "    sortidx = np.argsort(-classout)\n",
    "    print('Predicted dog breed, sorted by model output:')\n",
    "    print('\\nID\\tOutput\\tBreed name\\n')\n",
    "    for i, x, classname in zip(sortidx,classout[sortidx],classnames[sortidx]):\n",
    "        print('%d   \\t%1.3f %s\\t%s'%(i,x,'*' if selclass==i else ' ', classname))\n",
    "except:\n",
    "    print('There was an error accessing the API.')\n",
    "    print('Check:')\n",
    "    print('  - Model endpoint is In Service')\n",
    "    print('  - Lambda is using correct endpoint and is updated')\n",
    "    print('  - API is active and updated')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
