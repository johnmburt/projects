{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a SageMaker image-classifier microservice\n",
    "\n",
    "## Generate LST files for SageMaker model training and validation\n",
    "\n",
    "### Project for AICamp course: [Full Stack Deep Learning in AWS - Online](https://learn.xnextcon.com/course/courseDetails/C2031717)\n",
    "\n",
    "### John Burt    \n",
    "\n",
    "#### March 2020\n",
    "\n",
    "\n",
    "## The project\n",
    "For this project, the task was to create and train an image classifier using Amazon SageMaker, then deploy a classifier instance as a microservice via the AWS API Gateway. I chose to make a dog breed classifier using a set of images made available by Stanford University. \n",
    "\n",
    "### For more details, see my [project github site](https://github.com/johnmburt/projects/tree/master/AWS/sagemaker_dog_breed_id)\n",
    "\n",
    "\n",
    "## This notebook\n",
    "\n",
    "This notebook generates the LST files necessary to train and test the model using SageMaker explorer. LST files describe the samples to use for training and testing the model. These files are uploaded to the S3 bucket folder that contains the train/test images and are used in the training job setup.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func to read image paths from a folder and return LST data\n",
    "\n",
    "LST data is a tab delimited text file w/ cols:\n",
    "- sample id \n",
    "- class id \n",
    "- sample file path (rel to root folder)\n",
    "\n",
    "This code assumes images for each class are stored in separate subfolders in a root folder. The subfolder names are assumed to contain class name info and are returned in the dataframe so you can map class index to a class name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import fnmatch\n",
    "from datetime import datetime,timedelta  \n",
    "\n",
    "def read_image_lst_info(srcdir):\n",
    "    \"\"\"Walk through base folder and collect paths for all image files.\n",
    "        category info, return as a dataframe w/ \n",
    "        samp_index, cat_index, relpath, class name\"\"\"\n",
    "    \n",
    "    fileexts=['*.jpg']\n",
    "\n",
    "    # search through source folder for sample files\n",
    "    relpath = []\n",
    "    subdirname = []\n",
    "    for ext in fileexts:\n",
    "        for root, dirnames, filenames in os.walk(srcdir):\n",
    "            for filename in fnmatch.filter(filenames, ext):\n",
    "                subdir = root.split('\\\\')[-1]\n",
    "                relpath.append( subdir + '/' + filename)\n",
    "                subdirname.append(subdir)\n",
    "                \n",
    "    # make sample id\n",
    "    sampid = np.arange(len(subdirname))\n",
    "    \n",
    "    # subdir names will be used as class names\n",
    "    classnames = np.unique(subdirname)\n",
    "    \n",
    "    # generate class id for each sample\n",
    "    d = dict(zip(classnames,np.arange(len(classnames))))\n",
    "    classid = [d[x] for x in subdirname]\n",
    "    \n",
    "    # return dataframe with file info\n",
    "    return pd.DataFrame({'sampid': sampid, \n",
    "                         'classid':  classid,\n",
    "                         'path': relpath,\n",
    "                         'classname': subdirname} )   \n",
    "    \n",
    "# dir containing image files\n",
    "# NOTE: code assumes this script is run from directory \n",
    "#  containing srcdir.\n",
    "srcdir = './images'\n",
    "\n",
    "df = read_image_lst_info(srcdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate train/test split(s), save to LST files\n",
    "\n",
    "- Optionally, select a subset of classes: for model development and tuning with a large number of classes, it's faster to work with a subset initially, then train on the full set after you're satisfied with subset performance.\n",
    "\n",
    "\n",
    "- Shuffle samples, stratify to ensure sample frequencies are balanced, split into train and test sets. \n",
    "\n",
    "\n",
    "- If more than one split (n_splits>1), generate multiple sets of train/test samples, using K folds method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating train/test lst files:\n",
      "split 1\n",
      "  train: 1535 samples, 10 classes, dog_breeds_10_fold_1_train.lst\n",
      "  test: 384 samples, 10 classes, dog_breeds_10_fold_1_test.lst\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# num K folds train/test split sets you want to generate\n",
    "n_splits = 1 \n",
    "\n",
    "# None = select all classes\n",
    "n_classes = None \n",
    "\n",
    "# prefix for generated LST file names\n",
    "filenameroot = 'dog_breeds'\n",
    "\n",
    "# include all classes of image\n",
    "if n_classes is None:\n",
    "    filenameroot += '_all'\n",
    "    df_filt = df\n",
    "# include only the first specified number of classes\n",
    "else:\n",
    "    filenameroot += '_'+str(n_classes)\n",
    "    df_filt = df[df.classid<n_classes]\n",
    "\n",
    "# this split method ensures each class gets equal sample sizes\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "\n",
    "print('Generating train/test lst files:')\n",
    "for i, (train_index, test_index) in zip(range(n_splits), \n",
    "                    sss.split(df_filt, df_filt['classid'])):\n",
    "    df_train = df_filt.iloc[train_index,:3]\n",
    "    fname_train = filenameroot+'_fold_%d_train.lst'%(i+1)\n",
    "    df_train.to_csv(fname_train, index=False, header=False, sep='\\t')\n",
    "    \n",
    "    df_test = df_filt.iloc[test_index,:3]\n",
    "    fname_test = filenameroot+'_fold_%d_test.lst'%(i+1)\n",
    "    df_test.to_csv(fname_test,index=False, header=False, sep='\\t')\n",
    "    \n",
    "    print('split',i+1)\n",
    "    print('  train: %d samples, %d classes, %s'%(\n",
    "        df_train.shape[0], len(df_train.classid.unique()), fname_train))\n",
    "    print('  test: %d samples, %d classes, %s'%(\n",
    "        df_test.shape[0], len(df_test.classid.unique()), fname_test))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
