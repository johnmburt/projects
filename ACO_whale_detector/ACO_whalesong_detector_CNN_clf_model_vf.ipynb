{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring deep sea acoustic events\n",
    "## Whale song detector: CNN estimator model\n",
    "\n",
    "### Feb 2020 PDSG Applied Data Science Meetup series<br>John Burt\n",
    "\n",
    "### Session details\n",
    "\n",
    "For February’s four session meetup series we’ll be working with long term hydrophone recordings from University of Hawaii's Aloha Cabled Observatory (ACO - http://aco-ssds.soest.hawaii.edu), located at a depth of 4728m off Oahu. The recordings span a year and contain many acoustic events: wave movements, the sound of rain, ship noise, possible bomb noises, geologic activity and whale calls and songs. There is a wide range of project topics to explore: identifying and counting acoustic events such as whale calls, measuring daily or seasonal noise trends, measuring wave hydrodynamics, etc.\n",
    "\n",
    "### This notebook:\n",
    "\n",
    "I built a classifier model to detect whale vocalizations in the recording. For this I used a standard Tensorflow/Keras Convolutional Neural Network (CNN), with a sound spectrograph as input.\n",
    "\n",
    "The CNN model was trained using a generator function that combined background sounds from the hydrophone recording with whale vocalization clips selected from clean song recordings acquired from the Woods Hole Oceanographic Institution's Watkins Marine Mammal Sound Database. The generator function randomly combined noise and whale sounds so that each sample was unique.\n",
    "\n",
    "In this notebook, I take the following steps:\n",
    "\n",
    "- Build a sklearn CNN estimator model to classify audio clips as having whale song or not.\n",
    "- Train model using a generator function that creates unique samples (whale or no-whale).\n",
    "- Test model using a test set of whale sounds held out from training.\n",
    "- Scan a hydrophone recording with the model, save whale detections as audio clips\n",
    "\n",
    "Extra packages required:\n",
    "- librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# ---\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import soundfile as sf\n",
    "import bz2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the whale song detection model\n",
    "\n",
    "The model is defined as an sklearn estimator object. That allows me to easily run sklearn tools like kfolds cross validation and hyperparameter tuning.\n",
    "\n",
    "The network model I've chosen is a standard tensorflow/keras based CNN, commonly used to classify images. Model input is a audio spectrograph (a time x frequency representation of a sound). Spectrographs are equivalent to images, so a CNN model should be a good first choice.\n",
    "\n",
    "### The model layers:\n",
    "\n",
    "- Input (Spectrograph image)\n",
    "- Conv2D\n",
    "- MaxPooling2D\n",
    "- Conv2D\n",
    "- MaxPooling2D\n",
    "- Conv2D\n",
    "- MaxPooling2D\n",
    "- Conv2D\n",
    "- MaxPooling2D\n",
    "- Flatten\n",
    "- Dense\n",
    "- Output (no whale song, whale song present)\n",
    "\n",
    "### Model notes:\n",
    "\n",
    "- During testing I tried using BatchNormalization layers after each Conv2D. This yielded poor results, where often the model would never learn. Therefore BatchNormalization was omitted. \n",
    "\n",
    "\n",
    "- I also tried a Dropout layer after each Conv2D. These networks learned, but not faster or better than omitting Dropout. Therefore I've disabled Dropout.\n",
    "\n",
    "\n",
    "- The model uses a sample generator for training and testing. The generator combines background hydrophone noise with clean humpback whale song note clips to produce a simulation of whale song with the same background the detector will be dealing with in the recording. More details:\n",
    "    - Background sound was randomly sampled from the hydrophone recording and totalled about 9 hours of audio. I manually verified that the background audio had no whale song.\n",
    "    \n",
    "    - Target whale sounds were clipped from WHOI recordings. They ranged from 0.5 to 5 seconds long.\n",
    "    \n",
    "    - Both background sound and target sounds were scaled to +/- 1 amplitude. For generating training samples, target whale sounds were randomly attenuated before adding to background noise, to simulate the range of song amplitudes in the hydrophone recording.\n",
    "        \n",
    "    - A model input frame was created by randomly selecting a section of background noise, randomly selecting a target sound and adding the target to the noise at a random time point within the noise frame, attenuating the target to a random degree. The noise+whale waveform was converted into a spectrograph for model input.\n",
    "        \n",
    "    - Negative (no whale) samples were generated exactly like positive (whale present), except no target was added to the background.\n",
    "        \n",
    "    - For testing, a set of target notes were held out from training (same background was used for training and testing). The generator was then used to create a test set for validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from keras.utils import to_categorical\n",
    "# import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# sklearn estimator model format for sound detector\n",
    "class SoundDetector(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"recommender engine as an estimator\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "        samprate = 5000,\n",
    "        hoplength = None, # # samples between FFTs\n",
    "        fftsize = 512, # FFT size (#bins = fftsize/2)\n",
    "        framesize = 1000, # frame size, samples\n",
    "        targwtrange = [.05, .1], # test: 88% no white, 84% white\n",
    "        whitenpct = None, # whitening percentile (more==more whitening)\n",
    "        freqrange = [60,4000], # frequency range to keep\n",
    "        sampjitter = 2000, # time jitter range, samples\n",
    "        ptarget=0.5, # prob target sample in generated data\n",
    "        ):      \n",
    "        \n",
    "        \"\"\"\n",
    "        Called when initializing the model\n",
    "        \"\"\"\n",
    "        # model parameters\n",
    "        self.samprate = samprate\n",
    "        self.hoplength = hoplength\n",
    "        self.fftsize = fftsize\n",
    "        self.framesize = framesize\n",
    "        self.targwtrange = targwtrange\n",
    "        self.whitenpct = whitenpct\n",
    "        self.freqrange = freqrange\n",
    "        self.sampjitter = sampjitter\n",
    "        self.ptarget = ptarget \n",
    "        \n",
    "        self.CNN_model = None\n",
    "        self.train_targets = None\n",
    "        self.test_targets = None\n",
    "\n",
    "    # ******************************************************************\n",
    "    def set_params(self, **params):\n",
    "        self.__dict__.update(params)\n",
    "        \n",
    "    # ******************************************************************\n",
    "    def whiten_spec(self, spec, pctile=95):\n",
    "        \"\"\"Whiten the spectrograph by thresholding using the given percentile (0-100)\"\"\"\n",
    "        specw = spec.copy()\n",
    "        for row in range(spec.shape[0]):\n",
    "            specw[row,specw[row,:]<np.percentile(specw[row,:],pctile)] = 0\n",
    "        return specw\n",
    "    \n",
    "    # ******************************************************************\n",
    "    def make_spec(self, wave):\n",
    "        \"\"\"Generate a spectrograph of waveform data using the model parameters\"\"\"\n",
    "        # return whitened spec\n",
    "        if self.whitenpct is None:\n",
    "            return np.abs(librosa.stft(wave, hop_length=self.hoplength, n_fft=self.fftsize))\n",
    "        # return spec as-is\n",
    "        else:\n",
    "            return whiten_spec(np.abs(librosa.stft(wave, hop_length=self.hoplength, \n",
    "                                                   n_fft=self.fftsize)), whitenpct)\n",
    "\n",
    "    # ******************************************************************\n",
    "    def make_sample_spec(self, target, background, framesize,\n",
    "                          targwtrange=[1,1], whitenpct=None, hoplength=0, n_fft=256, \n",
    "                          samprate=4000, freqrange = [0,-1], sampjitter=0):\n",
    "        \"\"\"generate a sample spectrograph with target plus background noise\"\"\"\n",
    "\n",
    "        # add random jitter to where target sound starts in sample frame \n",
    "        jitter = int(np.random.random() * sampjitter*2 - sampjitter)\n",
    "        offset = max(0,min(framesize-len(target),jitter+int((framesize-len(target))/2)))\n",
    "\n",
    "        # weight the target, either fixed, or over random range\n",
    "        if targwtrange[1] == targwtrange[0]:\n",
    "            targetwt = targwtrange[1]\n",
    "        else:\n",
    "            targetwt = np.random.random() * (targwtrange[1]-targwtrange[0]) +  targwtrange[0]\n",
    "\n",
    "        # random select where frame starts in background noise \n",
    "        backstart = int((len(background) - framesize) * np.random.random())\n",
    "\n",
    "        # create frame of framesize length containing target, buffering as necessary\n",
    "        frame = np.zeros([framesize,]) \n",
    "        targetlen = min(len(target),framesize)\n",
    "        frame[offset:offset+targetlen] = target[:targetlen]*targetwt\n",
    "\n",
    "        # determine upper and lower frequency range bin indices \n",
    "        nbins = int(n_fft/2)\n",
    "        minbin = int(np.round(freqrange[0]*nbins*2/samprate))\n",
    "        if freqrange[1] > 0:\n",
    "            maxbin = min(nbins,int(np.round(freqrange[1]*nbins*2/samprate)))\n",
    "        else:\n",
    "            maxbin = nbins\n",
    "            \n",
    "        return self.make_spec(frame + background[backstart:backstart+framesize])\n",
    "\n",
    "    # ******************************************************************\n",
    "    def sample_generator(self, target, background, batch_size, framesize, targwtrange=[1,1], whitenpct=None, \n",
    "                         hoplength=0, n_fft=256, samprate=4000, freqrange = [0,-1], sampjitter=0, ptarget=0.5):\n",
    "        \"\"\"Generator to create batches of model training spectrograph samples.\n",
    "        For each sample, randomly combines a target sound with a background.\"\"\"\n",
    "\n",
    "        # create a sample frame to get spec dimensions. \n",
    "        tspec = self.make_sample_spec(target['wave'].iloc[0], background['wave'].iloc[0],\n",
    "                                 framesize, targwtrange=targwtrange, \n",
    "                                 whitenpct=whitenpct, freqrange=freqrange, hoplength=hoplength, \n",
    "                                 n_fft=fftsize, sampjitter=sampjitter)\n",
    "        # spec image dimensions\n",
    "        spec_x = tspec.shape[0]\n",
    "        spec_y = tspec.shape[1]\n",
    "        numchans = 1\n",
    "\n",
    "        # Create empty arrays to contain batch of X (features) and y (labels)\n",
    "        batch_X = np.zeros((batch_size, spec_x, spec_y, numchans))\n",
    "        batch_y = np.zeros((batch_size,))\n",
    "\n",
    "        # yield a batch of novel sample spectrograph images, \n",
    "        # randomly selected as containing whale or no-whale: \n",
    "        #  no-whale sample: background with no whale.\n",
    "        #  whale: background w/ whale song note added at random time, w/ random range of amplitude.\n",
    "        while True:\n",
    "            # random select target and background file path indices\n",
    "            id_idx = np.random.choice(range(target.shape[0]), size=batch_size)\n",
    "            back_idx = np.random.choice(range(background.shape[0]), size=batch_size)\n",
    "            speclist = []\n",
    "            y = []\n",
    "            for i, tid, bid in zip(range(len(id_idx)), id_idx, back_idx):\n",
    "                # is this a whale (target) or no-whale sample?\n",
    "                istarget = 1 if np.random.random() < ptarget else 0\n",
    "                batch_y[i] = istarget\n",
    "                # generate a spectrograph image and append to batch list\n",
    "                speclist.append(\n",
    "                    self.make_sample_spec(target['wave'].iloc[tid], background['wave'].iloc[bid],\n",
    "                        framesize, targwtrange=targwtrange if istarget else [0,0], \n",
    "                        whitenpct=whitenpct, freqrange=freqrange, hoplength=hoplength,\n",
    "                        n_fft=fftsize, sampjitter=sampjitter)            \n",
    "                        )\n",
    "            # convert list of 2D images to 3D array, rearrange axes\n",
    "            specs = np.moveaxis(np.dstack(speclist),[0,1,2], [1,2,0] )\n",
    "            # reshape array to X[sample#, image_width, image_height]\n",
    "            batch_X = specs.reshape(specs.shape[0], spec_x, spec_y, 1 )\n",
    "\n",
    "            # note that for now, I'm assuming only two classes: whale vs no-whale\n",
    "            yield batch_X, to_categorical(batch_y,num_classes=2)\n",
    "     \n",
    "    # ******************************************************************\n",
    "    def train_test_target_split(self, targets, testp=0.1):\n",
    "        \"\"\"Divide target sounds into train or test categories.\n",
    "        \n",
    "        This is needed to prevent info leakage into test set.\n",
    "        testp = proportion of target sounds used for testing.\n",
    "        Note: background sound is shared across train/test sets.\"\"\"\n",
    "        \n",
    "        # randomly select train and test IDs\n",
    "        target_ids = targets['id'].unique()\n",
    "        np.random.shuffle(target_ids)\n",
    "        n_testids = int(len(target_ids)*testp)\n",
    "        train_ids = target_ids[:-n_testids]\n",
    "        test_ids = target_ids[-n_testids:]\n",
    "\n",
    "        train_targets = targets[ [tid in train_ids for tid in targets['id']] ]\n",
    "        test_targets = targets[ [tid in test_ids for tid in targets['id']] ]\n",
    "\n",
    "        return train_targets, test_targets\n",
    "\n",
    "    # ******************************************************************\n",
    "    def create_validation_set(self, targets, backgrounds, num_samples):\n",
    "        \"\"\"Yield a single batch of samples to use as a validation set.\"\"\"\n",
    "        for X_test, y_test in self.sample_generator(targets, backgrounds, num_samples, \n",
    "                             self.framesize, targwtrange=self.targwtrange, whitenpct=self.whitenpct, \n",
    "                             hoplength=self.hoplength, n_fft=self.fftsize, samprate=self.samprate, \n",
    "                             freqrange=self.freqrange, sampjitter=self.sampjitter, ptarget=self.ptarget\n",
    "                            ):\n",
    "            break\n",
    "        return X_test, y_test\n",
    "    \n",
    "    # ******************************************************************\n",
    "    def create_network(self, input_shape):\n",
    "        \"\"\"Build and compile keras CNN model\"\"\"\n",
    "        \n",
    "        # params for each conv layer: #filters, #strides, pooling_size\n",
    "        convlayersize = [(2,7,(2,2),(2,2)), \n",
    "                         (4,3,(2,2),(2,2)),\n",
    "                         (8,3,(2,2),(2,2)),\n",
    "                         (16,3,(2,2),(2,2))\n",
    "                        ]\n",
    "        denselayersize = 100 # nodes in dense layer between C layers and output\n",
    "        num_classes = 2 # #output nodes\n",
    "        dropoutrate = 0 # dropout rate: 0 = no dropouts\n",
    "        usebatchnorm = False # flag to use batch normalization\n",
    "\n",
    "        model = Sequential()\n",
    "        firstlayer = True           \n",
    "        for (nfilters, kernelsize, strides, poolingsize) in convlayersize:\n",
    "            # first conv filter layer connects to input\n",
    "            if firstlayer:\n",
    "                firstlayer = False\n",
    "                model.add(Conv2D(nfilters, kernel_size=kernelsize, \n",
    "                                 input_shape=input_shape, \n",
    "                                 use_bias=False if usebatchnorm else True))\n",
    "            # hidden conv filter layers\n",
    "            else:\n",
    "                model.add(Conv2D(nfilters, kernel_size=kernelsize, \n",
    "                                 use_bias=False if usebatchnorm else True))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            if dropoutrate > 0: model.add(Dropout(dropoutrate))\n",
    "            if usebatchnorm: model.add(BatchNormalization())\n",
    "            model.add(MaxPooling2D(pool_size=poolingsize, strides=strides))\n",
    "\n",
    "        # dense post-CNN layer \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(denselayersize, activation='relu'))\n",
    "        \n",
    "        # output layer\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=tf.keras.optimizers.Adam(),\n",
    "                      metrics=['accuracy'])   \n",
    "        return model\n",
    "        \n",
    "    # ******************************************************************\n",
    "    def fit(self, train_targets, backgrounds, test_targets=None):\n",
    "        \"\"\" Train the model.\n",
    "        \"\"\"\n",
    "        num_validation_samples = 250\n",
    "        \n",
    "        # split targets into training and validation sets\n",
    "        if test_targets is not None:\n",
    "            X_test, y_test = self.create_validation_set(test_targets, backgrounds, num_validation_samples)\n",
    "        else:\n",
    "            X_test, y_test = self.create_validation_set(train_targets, backgrounds, 1)\n",
    "\n",
    "        # use test samples to get input shape for model training\n",
    "        input_shape = (X_test.shape[1], X_test.shape[2], 1)\n",
    "\n",
    "        # create the CNN model\n",
    "        self.CNN_model = self.create_network(input_shape)\n",
    "        \n",
    "        batch_size = 10\n",
    "        steps = batch_size*4\n",
    "        epochs = 15\n",
    "        updaterate = 5\n",
    "\n",
    "        # train model using sample generator method. \n",
    "        # This allows unique training samples to be generated every batch.\n",
    "        \n",
    "        # Train model using a validation set\n",
    "        if test_targets is not None:\n",
    "            self.CNN_model.fit_generator(\n",
    "                self.sample_generator(train_targets, backgrounds, batch_size, \n",
    "                                 self.framesize, targwtrange=self.targwtrange, whitenpct=self.whitenpct, \n",
    "                                 hoplength=self.hoplength, n_fft=self.fftsize, samprate=self.samprate, freqrange=self.freqrange, \n",
    "                                 sampjitter=self.sampjitter, ptarget=self.ptarget),\n",
    "                steps_per_epoch = steps,\n",
    "                epochs = epochs,\n",
    "                validation_data = (X_test, y_test),\n",
    "                verbose = 0\n",
    "                )\n",
    "        # Train model with no validation set\n",
    "        else:\n",
    "            self.CNN_model.fit_generator(\n",
    "                self.sample_generator(train_targets, backgrounds, batch_size, \n",
    "                                 self.framesize, targwtrange=self.targwtrange, whitenpct=self.whitenpct, \n",
    "                                 hoplength=self.hoplength, n_fft=self.fftsize, samprate=self.samprate, freqrange=self.freqrange, \n",
    "                                 sampjitter=self.sampjitter, ptarget=self.ptarget),\n",
    "                steps_per_epoch = steps,\n",
    "                epochs = epochs,\n",
    "                verbose = 0\n",
    "                )\n",
    "        return self\n",
    "        \n",
    "    # ******************************************************************\n",
    "    def predict(self, specframes):\n",
    "        \"\"\"predict whether a set of spectrographs formatted for \n",
    "        model input contains a target sound. Returns index of max output. \n",
    "        \"\"\"\n",
    "        # return index of highest level output (0 or 1)\n",
    "        return np.argmax(self.CNN_model.predict(specframes),axis=1) \n",
    "\n",
    "    # ******************************************************************\n",
    "    def predict_proba(self, specframes):\n",
    "        \"\"\"predict whether a set of spectrographs formatted for \n",
    "        model input contains a target sound. Returns model outputs.\n",
    "        \"\"\"\n",
    "        # treat model output as probability\n",
    "        return self.CNN_model.predict(specframes)                           \n",
    "\n",
    "    # ******************************************************************\n",
    "    def predict_from_wave(self, wave):\n",
    "        \"\"\"Predict whether a waveform contains target sound.\n",
    "        Returns index of max output.\n",
    "        This is used by the whale detector script.\"\"\"\n",
    "        numframes = int(wave.shape[0]/self.framesize)\n",
    "        speclist=[]\n",
    "        for fnum in range(numframes):\n",
    "            speclist.append(self.make_spec(wave[fnum*self.framesize:(fnum+1)*self.framesize]))\n",
    "        spec_x = speclist[0].shape[0]\n",
    "        spec_y = speclist[0].shape[1]\n",
    "        specs = np.moveaxis(np.dstack(speclist),[0,1,2], [1,2,0] )\n",
    "        X = specs.reshape(specs.shape[0], spec_x, spec_y, 1 )\n",
    "        pred = self.CNN_model.predict(X)\n",
    "        return np.argmax(pred,axis=1) \n",
    "\n",
    "    # ******************************************************************\n",
    "    def score(self, y_true, y_pred):\n",
    "        \"\"\"mean percent of y_true game IDs in y_pred\"\"\"\n",
    "        return  accuracy_score(y_true, y_pred)\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the train / test data\n",
    "\n",
    "The training audio consists of clean clips of whale song notes (training targets), and background sounds with no whale song that I randomly selected from the hydrophone recordings. In another notebook, I prepared the audio by resampling the targets and background noise to the same sample rate (5 kHz) and saved them to pandas dataframes in HDF5 format. This allows the training audio to be quickly loaded, ready to be used with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "datapath = './data/model/wavdata_v1.h5'\n",
    "\n",
    "targets = pd.read_hdf(datapath, key='target')\n",
    "backgrounds = pd.read_hdf(datapath, key='background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model params and a function to return an initialized model instance\n",
    "\n",
    "batch_size = 250 # #training samples per batch\n",
    "\n",
    "samprate = 5000 # audio sample rate\n",
    "fftsize = 512 # FFT size (#bins = fftsize/2)\n",
    "hoplength = None # #samples between FFTs (None = 1/4 fftsize)\n",
    "framesize = samprate * 4 # frame size, samples\n",
    "targwtrange = [.1, .2] # test: 93% no white, 95% white\n",
    "whitenpct = None # whitening percentile (more==more whitening)\n",
    "freqrange = [60,4000] # frequency range to keep\n",
    "sampjitter = int(framesize/2) # time jitter range, samples\n",
    "ptarget=0.5 # prob target sample in generated data\n",
    "\n",
    "def make_clf():\n",
    "    return SoundDetector(\n",
    "        samprate = samprate,\n",
    "        hoplength = hoplength, # # samples between FFTs\n",
    "        fftsize = fftsize, # FFT size (#bins = fftsize/2)\n",
    "        framesize = framesize, # frame size, samples\n",
    "        targwtrange = targwtrange, # test: 88% no white, 84% white\n",
    "        whitenpct = whitenpct, # whitening percentile (more==more whitening)\n",
    "        freqrange = freqrange, # frequency range to keep\n",
    "        sampjitter = sampjitter, # time jitter range, samples\n",
    "        ptarget=ptarget, # prob target sample in generated data\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validate the model\n",
    "\n",
    "Note that there are a number of parameters that define how the model creates input for training. I've manually experimented with these to find parameters that work pretty well. In the future, I'll tune these properly using hyperopt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 3s 11ms/sample - loss: 0.3513 - acc: 0.8760\n",
      "250/250 [==============================] - 3s 14ms/sample - loss: 0.3544 - acc: 0.8880\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.2016 - acc: 0.9280\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1871 - acc: 0.9360\n",
      "250/250 [==============================] - 4s 18ms/sample - loss: 0.1988 - acc: 0.9440\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1635 - acc: 0.9440\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1680 - acc: 0.9480\n",
      "250/250 [==============================] - 6s 23ms/sample - loss: 0.1476 - acc: 0.9520\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1371 - acc: 0.9480\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1327 - acc: 0.9520\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1345 - acc: 0.9560\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1225 - acc: 0.9480\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1240 - acc: 0.9560\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1202 - acc: 0.9480\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1164 - acc: 0.9560\n",
      "score= 0.956\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.4249 - acc: 0.8960\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.2330 - acc: 0.9280\n",
      "250/250 [==============================] - 4s 14ms/sample - loss: 0.3495 - acc: 0.9200\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.2594 - acc: 0.9120\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1906 - acc: 0.9280\n",
      "250/250 [==============================] - 6s 22ms/sample - loss: 0.1948 - acc: 0.9280\n",
      "250/250 [==============================] - 5s 21ms/sample - loss: 0.1991 - acc: 0.9520\n",
      "250/250 [==============================] - 4s 17ms/sample - loss: 0.1696 - acc: 0.9520\n",
      "250/250 [==============================] - 4s 16ms/sample - loss: 0.1655 - acc: 0.9520\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1563 - acc: 0.9560\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1933 - acc: 0.9160\n",
      "250/250 [==============================] - 5s 18ms/sample - loss: 0.1680 - acc: 0.9320\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1313 - acc: 0.9560\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1304 - acc: 0.9520\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1463 - acc: 0.9640\n",
      "score= 0.952\n",
      "250/250 [==============================] - 4s 14ms/sample - loss: 0.3438 - acc: 0.8520\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.2658 - acc: 0.9000\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.2332 - acc: 0.9040\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.2142 - acc: 0.9120\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.2287 - acc: 0.8960\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.2227 - acc: 0.9040\n",
      "250/250 [==============================] - 3s 14ms/sample - loss: 0.2471 - acc: 0.9200\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1880 - acc: 0.9200\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1925 - acc: 0.9360\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.2331 - acc: 0.9200\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1828 - acc: 0.9200\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1615 - acc: 0.9400\n",
      "250/250 [==============================] - 3s 14ms/sample - loss: 0.1702 - acc: 0.9320\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1786 - acc: 0.9440\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1773 - acc: 0.9320\n",
      "score= 0.942\n",
      "250/250 [==============================] - 4s 14ms/sample - loss: 0.4121 - acc: 0.8520\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.3209 - acc: 0.8520\n",
      "250/250 [==============================] - 5s 19ms/sample - loss: 0.2544 - acc: 0.9000\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.3069 - acc: 0.8600\n",
      "250/250 [==============================] - 4s 16ms/sample - loss: 0.2312 - acc: 0.9160\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.2226 - acc: 0.9040\n",
      "250/250 [==============================] - 4s 15ms/sample - loss: 0.2091 - acc: 0.9120\n",
      "250/250 [==============================] - 4s 14ms/sample - loss: 0.1780 - acc: 0.9320\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1965 - acc: 0.9240\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1581 - acc: 0.9280\n",
      "250/250 [==============================] - 4s 16ms/sample - loss: 0.1505 - acc: 0.9360\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1549 - acc: 0.9360\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1425 - acc: 0.9320\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.2206 - acc: 0.9240\n",
      "250/250 [==============================] - 4s 15ms/sample - loss: 0.1437 - acc: 0.9320\n",
      "score= 0.948\n",
      "250/250 [==============================] - 3s 14ms/sample - loss: 0.4606 - acc: 0.8040\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.3196 - acc: 0.8800\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.2607 - acc: 0.8840\n",
      "250/250 [==============================] - 4s 16ms/sample - loss: 0.2426 - acc: 0.9080\n",
      "250/250 [==============================] - 4s 15ms/sample - loss: 0.2254 - acc: 0.9120\n",
      "250/250 [==============================] - 3s 14ms/sample - loss: 0.2297 - acc: 0.9120\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.2261 - acc: 0.9240\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1941 - acc: 0.9280\n",
      "250/250 [==============================] - 4s 15ms/sample - loss: 0.2427 - acc: 0.8960\n",
      "250/250 [==============================] - 4s 17ms/sample - loss: 0.1915 - acc: 0.9200\n",
      "250/250 [==============================] - 3s 14ms/sample - loss: 0.1758 - acc: 0.9080\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1577 - acc: 0.9240\n",
      "250/250 [==============================] - 3s 13ms/sample - loss: 0.1782 - acc: 0.9240\n",
      "250/250 [==============================] - 3s 14ms/sample - loss: 0.1742 - acc: 0.9240\n",
      "250/250 [==============================] - 4s 15ms/sample - loss: 0.1591 - acc: 0.9360\n",
      "score= 0.938\n",
      "mean score = 0.947\n",
      "Wall time: 15min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "scores = []\n",
    "for train_index, test_index in kf.split(targets):\n",
    "    clf = make_clf() # create new model instance\n",
    "    # select train and test target waves\n",
    "    train_targets = targets.iloc[train_index,:]\n",
    "    test_targets = targets.iloc[test_index,:]\n",
    "    # train the model\n",
    "    clf.fit(train_targets, backgrounds, test_targets=test_targets)\n",
    "    # create a validation spectrograph set from the test target waves\n",
    "    X_test, y_test = clf.create_validation_set(test_targets, backgrounds, 500)\n",
    "    # predict target sound presence\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # generate a score\n",
    "    scores.append(clf.score(np.argmax(y_test,axis=1), y_pred))\n",
    "    print('score=',scores[-1])\n",
    "    \n",
    "print('mean score = %1.3f'%(np.mean(scores)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model on all targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SoundDetector(fftsize=512, framesize=20000, freqrange=[60, 4000],\n",
       "              hoplength=None, ptarget=0.5, sampjitter=10000, samprate=5000,\n",
       "              targwtrange=[0.1, 0.2], whitenpct=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train the model\n",
    "clf.fit(targets, backgrounds, test_targets=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scan a recording and predict whale song\n",
    "\n",
    "Now that the model is trained, it's time to test it out on a real hydrophone recording.\n",
    "\n",
    "For this task, I'll scan the \"every_other_hour\" recording that spans all of 2015, with 5 minutes of audio sampled every other hour. The script saves the audio for any frames the model classifies as having whale song to a detections folder for later review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "from datetime import datetime,timedelta  \n",
    "\n",
    "def read_clipnames(srcdir):\n",
    "    \"\"\"Walk through base folder and collect paths for all sound files.\n",
    "        parse date and time info, sort, and return as a dataframe\"\"\"\n",
    "    \n",
    "    clipexts=['*.mp3']\n",
    "    datefmt='%Y-%m-%d--%H.%M.mp3'\n",
    "\n",
    "    # search through source folder for sound files\n",
    "    # save clip path and date (parsed from filename)\n",
    "    clippath = []\n",
    "    clipdate = []\n",
    "    for ext in clipexts:\n",
    "        for root, dirnames, filenames in os.walk(srcdir):\n",
    "            for filename in fnmatch.filter(filenames, ext):\n",
    "                clippath.append(os.path.join(root, filename).replace('\\\\','/'))\n",
    "                clipdate.append(datetime.strptime(filename, datefmt))\n",
    "                \n",
    "    # get sort index\n",
    "    idx = np.argsort(clipdate)\n",
    "    # retun sorted dataframe\n",
    "    return pd.DataFrame({'date': np.array(clipdate)[idx], \n",
    "                       'path':  np.array(clippath)[idx]})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning recording:\n",
      "\n",
      "2015-01-01--04 56,64,68,76,156,192,\n",
      "2015-01-02--08 244,\n",
      "2015-01-02--20 60,68,76,88,96,104,120,140,164,172,180,192,200,208,\n",
      "2015-01-02--22 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,92,\n",
      "2015-01-03--00 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,80,84,88,92,96,104,108,112,116,120,124,128,132,136,140,144,152,160,168,172,176,180,184,188,192,196,200,204,208,212,220,224,228,240,248,256,260,268,276,280,284,288,292,\n",
      "2015-01-05--00 60,\n",
      "2015-01-05--02 0,164,\n",
      "2015-01-05--16 172,\n",
      "2015-01-05--22 164,\n",
      "2015-01-07--10 56,\n",
      "2015-01-07--12 156,\n",
      "2015-01-08--10 4,20,52,56,64,72,76,80,88,92,96,104,112,120,132,140,148,152,156,160,168,172,176,180,184,188,192,256,296,\n",
      "2015-01-08--12 4,16,20,28,32,48,52,56,60,64,68,76,84,88,92,96,100,104,108,116,124,132,140,144,148,152,156,160,164,168,172,176,184,192,200,204,208,212,216,220,224,228,236,244,248,256,260,264,272,280,284,292,\n",
      "2015-01-08--14 80,88,92,100,104,108,112,120,124,128,132,140,144,152,160,164,284,288,\n",
      "2015-01-08--16 72,100,108,112,116,120,124,128,132,136,140,144,152,160,164,168,192,208,220,232,240,248,264,276,280,288,292,\n",
      "2015-01-09--04 0,44,56,124,172,180,192,200,220,248,260,\n",
      "2015-01-10--14 184,240,\n",
      "2015-01-10--16 8,16,192,196,204,252,\n",
      "2015-01-10--18 236,\n",
      "2015-01-10--22 140,144,172,228,236,276,\n",
      "2015-01-11--00 120,132,144,152,160,184,196,208,212,216,\n",
      "2015-01-11--02 96,100,112,124,132,144,152,180,196,208,212,216,228,232,236,240,244,252,256,264,276,280,284,296,\n",
      "2015-01-11--04 56,68,72,84,88,92,100,104,112,116,120,124,128,136,140,144,148,152,156,160,164,168,172,176,180,184,192,196,200,204,208,212,216,220,224,228,232,244,252,256,260,264,280,288,292,\n",
      "2015-01-11--10 20,200,\n",
      "2015-01-11--12 56,224,276,\n",
      "2015-01-11--14 104,116,136,\n",
      "2015-01-11--16 92,100,120,140,160,184,192,228,260,264,268,272,276,280,284,288,292,\n",
      "2015-01-11--18 0,\n",
      "2015-01-11--20 40,\n",
      "2015-01-11--22 140,196,\n",
      "2015-01-12--00 112,\n",
      "2015-01-12--06 132,\n",
      "2015-01-12--16 44,76,\n",
      "2015-01-12--18 100,216,272,\n",
      "2015-01-12--20 208,\n",
      "2015-01-12--22 4,12,20,248,\n",
      "2015-01-13--00 32,\n",
      "2015-01-13--02 4,12,16,20,24,108,120,128,164,\n",
      "2015-01-13--04 4,12,16,24,32,36,40,44,48,52,56,60,64,68,76,80,84,88,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,\n",
      "2015-01-13--10 0,\n",
      "2015-01-13--12 68,80,88,92,\n",
      "2015-01-13--14 0,36,56,64,84,100,108,116,124,128,132,136,144,164,172,196,204,208,216,224,228,232,236,244,248,252,256,260,264,272,276,280,288,292,\n",
      "2015-01-13--16 0,8,20,32,40,52,56,60,72,80,92,100,112,132,144,152,164,172,184,192,204,212,224,\n",
      "2015-01-13--18 0,16,24,32,48,56,60,72,92,132,140,148,156,164,176,180,184,192,200,204,208,216,224,276,288,292,\n",
      "2015-01-13--20 8,16,24,32,72,84,96,104,112,116,120,124,132,136,140,144,152,156,160,164,168,172,180,184,196,204,208,212,216,228,236,244,248,252,276,292,\n",
      "2015-01-13--22 12,48,56,76,84,\n",
      "2015-01-14--00 16,24,196,200,204,212,220,228,232,236,244,260,\n",
      "2015-01-14--18 4,12,28,36,60,\n",
      "2015-01-14--20 44,112,\n",
      "2015-01-14--22 0,4,8,12,16,20,24,28,32,36,44,48,52,56,60,64,68,72,76,84,124,164,172,180,200,208,236,240,248,252,256,260,268,272,280,\n",
      "2015-01-15--00 16,32,56,60,68,72,76,80,84,88,92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,212,220,224,228,232,236,240,244,248,252,256,264,268,272,276,284,292,296,\n",
      "2015-01-15--02 24,32,36,44,48,56,64,68,88,172,180,188,192,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,\n",
      "2015-01-15--04 148,156,160,164,168,180,184,192,200,212,220,224,232,240,244,248,252,256,260,264,268,272,276,280,284,288,292,\n",
      "2015-01-15--10 144,164,168,172,176,180,184,188,192,196,200,204,208,216,220,224,228,\n",
      "2015-01-15--14 188,\n",
      "2015-01-15--16 0,4,8,12,16,20,24,28,32,36,40,48,52,56,60,68,84,88,100,104,108,120,124,128,136,144,152,160,164,168,184,188,196,200,204,208,212,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,\n",
      "2015-01-15--18 0,4,12,20,24,32,36,44,52,56,64,68,76,200,204,224,232,236,244,252,256,260,264,268,272,276,280,284,288,296,\n",
      "2015-01-15--20 0,4,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,80,84,88,92,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,\n",
      "2015-01-15--22 0,12,24,32,168,176,184,188,192,196,200,204,208,212,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,\n",
      "2015-01-16--00 0,4,8,12,16,20,24,28,32,36,40,48,52,60,64,68,72,80,88,92,96,100,108,112,116,120,128,136,144,148,152,156,160,164,168,176,184,192,196,204,240,244,276,284,292,\n",
      "2015-01-16--02 4,20,24,28,36,52,64,72,92,144,216,224,248,\n",
      "2015-01-16--04 20,84,100,120,124,128,148,152,160,164,256,\n",
      "2015-01-16--06 192,\n",
      "2015-01-16--08 188,\n",
      "2015-01-16--14 288,\n",
      "2015-01-16--16 240,\n",
      "2015-01-16--18 4,12,16,24,32,40,124,140,144,152,156,160,164,168,172,180,188,196,200,204,212,216,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,\n",
      "2015-01-16--20 0,4,8,12,16,24,32,40,48,56,60,68,96,100,128,180,228,232,236,252,260,268,276,280,284,288,292,296,\n",
      "2015-01-16--22 40,56,64,72,80,88,96,104,112,128,180,184,188,192,196,200,208,212,220,232,\n",
      "2015-01-17--00 120,124,128,136,144,152,160,164,168,172,176,180,188,196,204,212,220,228,236,244,252,260,268,272,276,284,288,292,\n",
      "2015-01-17--02 28,40,48,56,60,64,68,72,76,80,84,104,136,164,172,188,200,212,224,240,248,256,272,276,284,292,\n",
      "2015-01-17--22 256,\n",
      "2015-01-18--20 160,196,\n",
      "2015-01-18--22 100,104,112,124,128,132,168,184,252,256,260,264,268,272,276,280,288,292,296,\n",
      "2015-01-19--00 248,\n",
      "2015-01-19--02 228,244,272,280,\n",
      "2015-01-19--18 220,248,256,264,272,\n",
      "2015-01-20--00 0,4,8,76,100,104,120,148,152,164,172,176,180,184,188,192,196,200,204,208,216,220,228,232,256,\n",
      "2015-01-20--02 180,256,\n",
      "2015-01-20--04 16,\n",
      "2015-01-20--06 84,152,\n",
      "2015-01-20--16 0,8,28,40,44,52,72,124,\n",
      "2015-01-20--20 196,\n",
      "2015-01-21--00 24,\n",
      "2015-01-22--00 148,188,\n",
      "2015-01-22--18 144,\n",
      "2015-01-22--20 176,192,\n",
      "2015-01-23--00 260,\n",
      "2015-01-23--02 24,32,44,48,52,56,64,68,76,80,100,104,112,124,272,\n",
      "2015-01-23--06 160,\n",
      "2015-01-23--20 192,\n",
      "2015-01-23--22 12,\n",
      "2015-01-24--04 192,196,204,228,296,\n",
      "2015-01-24--20 16,32,216,280,292,296,\n",
      "2015-01-24--22 172,204,\n",
      "2015-01-25--00 228,244,284,292,\n",
      "2015-01-25--10 44,\n",
      "2015-01-25--18 72,108,116,152,176,212,220,276,284,292,\n",
      "2015-01-25--20 220,\n",
      "2015-01-26--18 56,\n",
      "2015-01-27--00 240,\n",
      "2015-01-27--12 220,\n",
      "2015-01-27--18 268,288,296,\n",
      "2015-01-27--20 20,36,44,60,72,80,88,96,104,112,172,192,200,212,216,220,228,236,244,252,264,272,280,288,\n",
      "2015-01-27--22 8,24,32,40,48,56,60,64,72,76,80,84,88,92,108,112,116,140,148,152,156,176,192,208,236,252,296,\n",
      "2015-01-28--14 280,\n",
      "2015-01-28--18 44,176,180,188,192,196,200,204,208,212,216,220,224,228,236,240,252,264,272,276,280,\n",
      "2015-01-28--20 8,48,76,80,92,96,104,108,112,120,128,144,160,164,176,264,272,280,\n",
      "2015-01-28--22 44,\n",
      "2015-01-29--00 0,4,8,16,20,24,28,32,36,40,44,48,52,60,64,68,72,76,80,84,88,92,96,100,104,108,112,116,120,124,128,132,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,208,212,216,220,224,228,236,240,244,248,252,256,260,268,272,276,280,284,288,292,296,\n",
      "2015-01-29--02 0,4,12,16,20,24,28,32,36,40,44,48,52,56,64,72,80,84,88,92,96,100,108,116,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,256,264,268,272,276,280,288,296,\n",
      "2015-01-29--04 0,4,12,16,20,24,28,32,36,40,52,60,132,144,152,156,164,168,176,184,188,196,\n",
      "2015-01-29--06 0,4,8,12,16,20,24,28,32,36,40,44,52,56,60,64,68,72,76,80,84,88,92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,180,184,188,192,200,212,220,232,240,244,248,260,264,272,276,280,284,292,296,\n",
      "2015-01-29--08 8,12,52,56,60,64,68,72,76,80,84,88,100,108,116,140,148,152,156,164,168,172,176,188,192,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,264,272,280,284,288,\n",
      "2015-01-29--10 188,220,228,264,\n",
      "2015-01-29--18 56,88,100,124,\n",
      "2015-01-29--20 52,204,228,240,248,256,260,264,268,276,284,292,296,\n",
      "2015-01-29--22 4,8,100,104,112,116,128,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,224,228,232,236,244,248,264,284,292,\n",
      "2015-01-30--00 0,20,28,48,76,92,112,120,156,176,260,268,\n",
      "2015-01-30--02 12,124,136,144,148,\n",
      "2015-01-30--04 24,80,92,100,104,128,136,144,152,156,168,172,176,180,188,196,200,208,216,228,232,240,244,248,252,256,260,264,268,272,276,284,288,292,\n",
      "2015-01-30--06 8,12,20,32,40,44,48,56,140,176,184,188,200,240,256,260,264,268,276,284,292,\n",
      "2015-01-30--08 112,136,152,260,\n",
      "2015-01-30--10 16,28,36,44,48,56,60,68,84,148,184,188,192,200,208,212,216,224,236,252,260,276,\n",
      "2015-01-30--12 84,92,136,140,148,152,160,168,172,180,192,\n",
      "2015-01-30--14 0,4,12,24,36,40,44,52,56,60,76,80,88,96,100,108,112,124,148,156,164,212,224,228,240,248,256,268,280,284,288,296,\n",
      "2015-01-30--16 0,12,28,48,144,148,164,168,176,188,252,272,\n",
      "2015-01-30--18 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,80,84,88,92,96,100,104,108,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,220,228,236,244,248,252,256,260,264,268,276,280,288,292,\n",
      "2015-01-30--20 0,4,8,12,16,36,68,76,80,88,92,96,104,108,148,152,180,188,192,208,212,220,228,232,236,240,244,248,252,256,260,264,268,276,284,292,\n",
      "2015-01-30--22 4,12,28,36,40,44,48,52,56,60,68,72,80,84,88,92,96,100,108,116,120,124,128,132,136,144,152,160,164,168,172,180,188,192,200,208,216,272,280,284,292,\n",
      "2015-01-31--00 0,4,12,20,24,28,32,36,40,52,60,64,76,84,88,92,96,104,112,120,128,132,136,140,148,164,168,176,180,184,228,240,248,256,260,268,276,\n",
      "2015-01-31--20 40,48,52,60,72,\n",
      "2015-01-31--22 168,212,220,252,\n",
      "2015-02-01--00 128,136,168,\n",
      "2015-02-01--04 124,128,136,140,148,160,\n",
      "2015-02-01--08 208,\n",
      "2015-02-02--08 44,64,76,\n",
      "2015-02-03--02 72,200,\n",
      "2015-02-03--04 268,\n",
      "2015-02-03--18 104,240,276,\n",
      "2015-02-03--22 48,52,68,76,92,124,164,192,200,224,288,292,296,\n",
      "2015-02-04--02 268,280,284,\n",
      "2015-02-04--04 32,40,52,\n",
      "2015-02-04--06 76,96,120,156,212,268,\n",
      "2015-02-04--10 208,240,268,280,288,\n",
      "2015-02-04--12 20,56,\n",
      "2015-02-04--16 24,28,92,100,104,120,124,132,228,264,268,284,292,296,\n",
      "2015-02-04--18 108,156,\n",
      "2015-02-04--20 52,\n",
      "2015-02-04--22 0,20,36,112,156,\n",
      "2015-02-05--00 172,\n",
      "2015-02-05--12 4,48,68,76,84,\n",
      "2015-02-05--14 44,\n",
      "2015-02-05--18 8,48,68,76,92,172,\n",
      "2015-02-05--22 64,\n",
      "2015-02-06--04 144,\n",
      "2015-02-09--18 4,\n",
      "2015-02-10--00 24,44,128,148,156,164,172,188,196,204,208,212,216,228,236,248,268,276,280,288,292,\n",
      "2015-02-10--02 0,12,20,\n",
      "2015-02-10--04 56,196,264,\n",
      "2015-02-10--18 160,172,180,184,\n",
      "2015-02-11--00 0,\n",
      "2015-02-11--08 264,\n",
      "2015-02-12--06 292,\n",
      "2015-02-12--18 40,48,52,\n",
      "2015-02-12--22 196,240,\n",
      "2015-02-13--00 28,36,44,72,88,\n",
      "2015-02-13--02 176,\n",
      "2015-02-13--08 44,\n",
      "2015-02-13--18 68,\n",
      "2015-02-13--22 124,208,\n",
      "2015-02-14--00 188,\n",
      "2015-02-14--16 72,\n",
      "2015-02-14--18 0,8,12,16,20,24,28,32,36,40,44,52,56,60,64,72,76,80,88,96,100,104,108,112,116,124,128,132,136,140,144,148,152,156,160,164,168,172,176,184,188,192,196,204,208,212,216,220,228,236,240,244,248,252,256,264,268,276,280,284,288,292,\n",
      "2015-02-14--20 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,68,72,76,80,84,88,96,100,104,108,112,116,120,124,128,132,136,140,144,148,156,164,176,184,192,200,204,208,212,216,220,224,228,232,236,240,244,248,256,260,264,268,276,280,284,288,292,\n",
      "2015-02-14--22 0,4,8,12,16,20,24,36,40,44,48,52,56,60,64,72,80,84,88,92,96,100,104,108,116,124,132,140,144,148,180,188,200,208,216,\n",
      "2015-02-15--00 0,4,8,12,16,20,36,48,\n",
      "2015-02-15--04 28,\n",
      "2015-02-15--12 248,252,\n",
      "2015-02-15--18 36,64,76,80,108,128,144,164,\n",
      "2015-02-16--02 196,204,212,220,228,236,244,296,\n",
      "2015-02-16--04 264,268,\n",
      "2015-02-16--12 96,\n",
      "2015-02-16--22 32,\n",
      "2015-02-17--00 36,44,\n",
      "2015-02-17--04 280,292,\n",
      "2015-02-17--06 132,148,172,200,208,216,\n",
      "2015-02-17--18 36,\n",
      "2015-02-17--20 4,44,52,56,64,68,76,84,88,160,168,176,184,196,204,208,212,216,224,228,232,236,240,244,252,256,260,264,268,272,276,284,296,\n",
      "2015-02-17--22 0,4,8,12,16,20,28,32,36,52,60,72,108,112,116,128,136,140,160,176,184,188,196,200,208,212,232,252,272,276,280,284,\n",
      "2015-02-18--00 4,8,12,16,24,28,32,36,40,44,56,60,64,68,72,76,80,84,88,92,96,100,104,108,112,116,128,136,148,156,176,180,188,192,196,200,204,208,216,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,\n",
      "2015-02-18--02 0,4,8,16,20,24,28,32,36,44,52,56,60,64,68,72,76,84,88,92,96,100,112,120,124,132,140,148,160,168,180,188,192,196,200,204,208,212,216,224,228,236,260,264,268,272,276,280,284,288,292,296,\n",
      "2015-02-18--04 0,4,8,16,20,24,28,32,36,44,52,60,64,76,120,124,132,156,168,172,176,180,184,188,192,196,200,208,216,240,248,252,256,260,264,268,272,280,\n",
      "2015-02-18--14 220,\n",
      "2015-02-18--16 172,184,192,200,208,212,260,264,272,\n",
      "2015-02-18--18 144,216,220,228,276,292,\n",
      "2015-02-18--20 8,16,28,36,40,56,84,176,196,240,256,260,288,292,\n",
      "2015-02-19--00 80,176,\n",
      "2015-02-19--02 84,\n",
      "2015-02-19--04 120,\n",
      "2015-02-19--18 196,208,268,\n",
      "2015-02-19--22 8,44,60,64,72,80,92,108,128,136,156,164,184,188,296,\n",
      "2015-02-20--00 0,8,24,28,40,48,64,68,76,80,84,240,248,252,260,264,272,276,284,\n",
      "2015-02-20--02 40,\n",
      "2015-02-20--04 4,12,\n",
      "2015-02-20--10 0,4,8,12,20,24,28,40,44,48,52,56,60,64,68,72,76,80,84,88,92,96,100,104,108,116,124,128,132,136,140,144,148,152,156,160,164,168,172,180,184,188,192,204,236,280,284,288,292,296,\n",
      "2015-02-20--14 96,\n",
      "2015-02-21--00 176,180,\n",
      "2015-02-21--02 4,24,32,36,52,60,68,80,88,136,144,148,156,\n",
      "2015-02-21--04 4,8,20,40,64,112,116,124,128,136,140,152,160,164,172,176,184,188,212,216,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,\n",
      "2015-02-21--06 12,28,36,44,56,200,204,212,220,224,228,232,236,240,252,256,\n",
      "2015-02-21--08 60,64,72,76,80,84,88,92,96,100,108,132,152,184,188,196,208,248,252,264,272,284,292,\n",
      "2015-02-21--20 4,12,20,24,44,52,64,92,276,\n",
      "2015-02-21--22 12,220,248,276,292,\n",
      "2015-02-22--00 268,\n",
      "2015-02-22--02 4,16,20,84,88,116,124,144,192,220,228,240,248,252,264,268,292,\n",
      "2015-02-22--04 16,24,28,32,40,44,52,60,64,68,76,80,88,96,104,112,116,124,136,140,144,148,156,164,172,220,272,292,296,\n",
      "2015-02-22--10 140,\n",
      "2015-02-22--12 28,72,224,264,\n",
      "2015-02-22--20 0,8,12,16,24,48,68,96,104,108,116,120,128,140,148,160,180,192,200,220,228,240,248,276,288,296,\n",
      "2015-02-22--22 8,16,28,36,88,92,96,100,104,116,184,212,232,248,256,264,268,272,276,288,\n",
      "2015-02-23--00 0,8,16,20,\n",
      "2015-02-23--04 0,8,12,16,20,32,40,44,52,60,64,72,80,92,100,112,120,132,140,152,160,172,180,184,240,248,256,268,288,\n",
      "2015-02-23--12 32,272,\n",
      "2015-02-23--14 132,180,\n",
      "2015-02-23--18 28,32,36,44,48,52,56,60,64,72,80,88,96,104,112,116,124,132,140,148,156,168,240,276,\n",
      "2015-02-23--20 0,12,24,32,36,44,64,156,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,224,232,236,240,248,252,256,260,264,268,272,276,280,284,288,292,\n",
      "2015-02-23--22 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,80,84,88,100,108,112,116,140,144,148,152,160,164,168,172,180,184,188,192,200,204,208,212,216,220,224,228,232,236,240,248,252,256,260,268,272,276,284,292,\n",
      "2015-02-24--00 0,4,8,16,20,28,36,44,48,56,176,180,188,200,204,208,220,228,252,260,268,\n",
      "2015-02-24--02 36,44,60,64,72,80,84,88,96,104,112,120,124,136,140,148,164,240,\n",
      "2015-02-24--14 16,148,\n",
      "2015-02-25--00 236,280,\n",
      "2015-02-25--06 188,\n",
      "2015-02-25--12 88,\n",
      "2015-02-25--14 40,276,\n",
      "2015-02-25--18 212,216,\n",
      "2015-02-26--08 268,\n",
      "2015-02-26--10 136,\n",
      "2015-02-26--16 124,132,136,140,144,152,164,172,184,208,216,236,\n",
      "2015-02-27--00 48,\n",
      "2015-02-27--04 4,8,12,16,20,24,28,36,44,48,60,68,72,76,80,88,92,96,104,112,116,120,124,128,136,140,156,160,164,172,176,180,184,192,196,200,208,220,224,232,236,244,272,\n",
      "2015-02-27--12 188,\n",
      "2015-02-27--18 288,292,\n",
      "2015-02-27--20 104,\n",
      "2015-02-27--22 28,\n",
      "2015-02-28--02 128,\n",
      "2015-02-28--04 288,\n",
      "2015-02-28--06 84,136,148,156,236,\n",
      "2015-02-28--12 32,\n",
      "2015-02-28--14 8,\n",
      "2015-02-28--18 64,\n",
      "2015-02-28--20 132,140,144,152,156,160,168,172,180,188,192,200,208,220,228,240,248,\n",
      "2015-02-28--22 4,12,16,20,24,28,32,40,52,60,68,72,80,88,100,108,120,128,\n",
      "2015-03-01--00 0,8,12,20,24,32,92,104,128,140,152,164,168,176,180,188,220,224,232,236,244,248,256,260,268,272,276,280,288,292,296,\n",
      "2015-03-01--02 8,108,120,124,132,136,144,148,156,160,168,204,216,228,240,244,252,260,264,268,272,276,280,284,292,296,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-03-01--04 0,4,12,24,32,36,40,44,52,56,60,64,72,76,80,84,88,92,100,104,108,112,120,128,136,140,148,152,156,160,168,172,180,188,192,200,208,212,216,220,228,232,236,240,244,248,252,256,260,268,272,276,280,284,288,296,\n",
      "2015-03-01--06 4,8,12,20,24,28,36,40,48,56,60,68,76,84,88,92,96,100,104,108,112,116,124,128,136,144,148,156,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,224,232,236,240,244,252,256,260,264,272,276,280,284,292,296,\n",
      "2015-03-01--10 240,248,260,268,280,284,288,292,\n",
      "2015-03-01--12 136,204,\n",
      "2015-03-01--20 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,64,68,72,76,80,84,88,92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,160,164,168,176,180,184,188,192,196,200,204,208,212,216,220,224,228,232,236,240,248,256,268,276,288,\n",
      "2015-03-01--22 0,4,8,12,16,24,28,32,36,44,56,60,64,76,80,84,92,96,100,104,116,120,124,128,152,176,180,184,196,200,288,292,296,\n",
      "2015-03-02--00 0,4,8,12,16,20,24,28,32,36,40,44,176,196,\n",
      "2015-03-02--02 76,88,100,\n",
      "2015-03-02--04 0,4,8,16,20,28,40,44,48,56,64,68,80,88,100,108,120,128,140,148,160,192,224,260,\n",
      "2015-03-02--06 0,48,56,116,120,128,132,136,140,148,152,156,160,168,172,176,180,188,192,200,228,232,244,248,260,\n",
      "2015-03-02--08 16,20,24,28,36,40,44,48,56,60,64,68,72,76,80,88,92,96,100,108,112,116,120,128,136,140,148,160,168,172,180,188,196,204,216,224,232,244,252,260,264,280,288,296,\n",
      "2015-03-02--12 12,24,32,44,52,72,84,112,152,164,172,184,192,204,212,224,232,244,252,264,272,284,292,\n",
      "2015-03-02--16 284,\n",
      "2015-03-02--20 4,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,80,84,88,96,100,104,108,112,116,120,124,128,132,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,\n",
      "2015-03-02--22 0,4,8,12,24,32,44,256,272,292,\n",
      "2015-03-03--00 4,12,20,24,44,56,60,64,76,84,96,108,112,116,140,148,168,180,184,188,200,216,232,240,\n",
      "2015-03-03--02 4,12,24,32,44,52,60,72,80,92,104,128,164,176,216,228,284,\n",
      "2015-03-03--10 0,8,12,20,24,28,32,40,44,48,56,76,80,84,88,92,100,104,108,112,116,120,124,128,132,140,144,148,152,156,160,164,172,184,192,196,200,204,216,224,232,244,252,256,264,272,280,\n",
      "2015-03-03--14 176,\n",
      "2015-03-03--16 252,260,268,\n",
      "2015-03-03--18 0,4,12,20,24,32,36,40,44,48,52,56,64,72,76,80,84,88,92,100,104,112,116,120,124,136,144,148,156,168,172,176,188,200,204,212,216,220,232,252,256,260,264,272,276,280,284,288,292,296,\n",
      "2015-03-03--20 4,12,20,36,40,44,48,56,64,84,92,96,100,112,120,128,136,140,160,172,176,212,256,\n",
      "2015-03-03--22 32,40,180,204,252,\n",
      "2015-03-04--00 72,136,148,152,156,160,168,188,196,204,224,232,236,252,264,272,\n",
      "2015-03-04--02 36,44,56,92,100,108,136,156,164,184,192,204,212,216,224,236,248,252,284,288,292,296,\n",
      "2015-03-04--04 100,112,116,168,176,\n",
      "2015-03-04--06 184,188,216,224,\n",
      "2015-03-04--08 212,224,232,272,280,288,\n",
      "2015-03-04--10 4,8,60,68,76,96,100,104,140,152,\n",
      "2015-03-04--12 20,88,96,100,116,220,\n",
      "2015-03-04--14 0,8,100,128,156,168,176,240,256,296,\n",
      "2015-03-04--18 0,4,12,16,20,24,32,40,44,52,60,64,72,80,84,92,96,100,104,112,120,128,132,140,148,156,160,172,176,180,200,248,256,260,272,280,\n",
      "2015-03-04--20 68,\n",
      "2015-03-04--22 48,204,216,\n",
      "2015-03-05--00 28,64,68,\n",
      "2015-03-05--02 0,4,8,12,16,20,28,32,36,40,48,52,56,60,68,72,76,80,84,88,92,96,100,104,108,112,116,120,128,136,140,148,156,160,168,176,184,192,200,204,208,220,248,260,\n",
      "2015-03-05--04 84,88,96,104,108,116,120,124,128,136,140,148,152,156,160,164,168,176,180,184,188,192,200,204,208,216,220,224,228,232,240,244,248,252,256,260,264,268,272,276,284,288,292,296,\n",
      "2015-03-05--06 40,48,52,60,64,140,\n",
      "2015-03-05--08 36,40,44,68,76,96,104,116,132,144,160,240,244,252,260,264,292,\n",
      "2015-03-05--14 264,276,\n",
      "2015-03-05--20 104,152,164,\n",
      "2015-03-05--22 8,24,\n",
      "2015-03-06--02 84,\n",
      "2015-03-06--04 0,8,20,28,36,40,48,56,64,80,84,228,\n",
      "2015-03-06--06 172,\n",
      "2015-03-06--08 4,8,12,16,24,32,36,40,44,48,52,56,60,68,72,76,80,84,88,92,96,104,108,116,120,124,132,144,152,160,164,172,184,188,200,284,\n",
      "2015-03-06--10 0,8,12,16,20,24,28,32,36,44,52,56,60,68,72,80,88,100,108,120,128,140,148,180,188,196,200,208,212,216,220,232,236,240,244,256,264,272,276,\n",
      "2015-03-06--12 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,80,84,88,92,96,100,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,212,228,232,240,244,248,252,256,264,268,272,276,292,\n",
      "2015-03-06--14 0,4,8,12,16,20,24,32,40,44,48,52,56,60,64,72,76,80,84,92,96,100,116,124,128,132,136,140,144,152,160,168,180,200,204,212,220,228,236,240,248,256,260,264,272,276,280,284,288,292,296,\n",
      "2015-03-06--18 0,4,8,16,24,28,32,40,44,52,64,72,76,80,84,92,176,208,\n",
      "2015-03-06--20 4,8,20,28,44,48,52,64,68,80,84,88,96,100,104,108,116,120,124,128,132,136,140,144,148,152,156,160,164,168,176,188,196,200,216,220,224,232,236,252,256,260,264,268,272,276,284,288,292,296,\n",
      "2015-03-06--22 0,4,8,12,16,20,24,28,36,40,44,52,56,60,64,68,72,80,84,88,96,100,104,108,112,116,120,124,128,136,144,152,156,164,172,\n",
      "2015-03-07--00 48,56,108,124,128,136,140,148,156,168,176,184,192,212,220,228,240,248,256,264,268,272,276,280,284,292,296,\n",
      "2015-03-07--02 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,80,84,88,92,96,100,104,108,112,120,124,128,132,136,140,148,152,156,160,164,168,172,176,180,184,188,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,268,\n",
      "2015-03-07--04 0,4,40,44,52,60,64,72,80,100,108,120,132,136,144,152,156,164,168,176,180,184,188,192,196,268,272,280,284,288,292,296,\n",
      "2015-03-07--06 0,\n",
      "2015-03-07--08 140,\n",
      "2015-03-07--12 240,\n",
      "2015-03-07--18 0,8,44,52,56,64,\n",
      "2015-03-08--02 164,\n",
      "2015-03-09--04 148,\n",
      "2015-03-09--06 252,\n",
      "2015-03-09--08 140,144,152,\n",
      "2015-03-09--12 4,36,292,\n",
      "2015-03-09--14 232,236,244,252,256,264,272,292,\n",
      "2015-03-09--16 8,20,32,40,60,68,\n",
      "2015-03-09--18 264,276,280,292,\n",
      "2015-03-09--20 28,36,104,\n",
      "2015-03-09--22 8,116,144,176,188,\n",
      "2015-03-10--00 0,32,40,52,112,148,180,\n",
      "2015-03-10--10 0,4,8,\n",
      "2015-03-10--12 60,\n",
      "2015-03-10--16 200,\n",
      "2015-03-10--20 280,288,\n",
      "2015-03-11--00 4,8,12,16,20,24,28,36,40,44,48,56,64,68,76,84,88,92,96,104,112,120,132,140,156,164,184,204,240,\n",
      "2015-03-11--02 4,132,136,144,152,160,168,172,176,180,184,188,192,200,204,208,212,224,228,232,236,240,248,252,256,264,272,284,288,292,296,\n",
      "2015-03-11--04 220,\n",
      "2015-03-11--06 36,40,44,180,196,200,204,\n",
      "2015-03-11--08 284,\n",
      "2015-03-11--10 16,\n",
      "2015-03-11--12 156,244,\n",
      "2015-03-11--14 268,\n",
      "2015-03-11--16 260,264,\n",
      "2015-03-11--18 92,112,116,124,164,232,\n",
      "2015-03-11--20 0,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,80,84,88,100,108,120,124,128,168,172,180,188,192,196,200,204,212,216,224,236,240,252,260,264,280,288,\n",
      "2015-03-11--22 0,4,8,12,16,24,28,32,36,40,48,56,88,100,104,120,132,144,164,176,184,188,196,200,212,224,236,268,296,\n",
      "2015-03-12--00 0,4,8,12,16,24,32,40,52,72,104,112,124,128,132,144,156,160,164,172,176,188,196,236,256,\n",
      "2015-03-12--02 0,8,20,28,44,68,96,136,140,144,148,152,156,160,164,168,172,180,184,200,208,212,220,228,236,240,248,256,260,264,268,272,276,280,284,288,296,\n",
      "2015-03-12--04 0,4,8,12,16,20,28,32,36,40,44,48,52,56,60,64,68,72,76,80,84,88,92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,204,208,212,216,220,224,228,232,240,244,248,252,256,260,264,272,276,280,288,292,296,\n",
      "2015-03-12--08 176,\n",
      "2015-03-12--10 16,24,36,64,160,216,\n",
      "2015-03-12--18 0,8,244,248,256,260,264,268,272,276,280,284,288,292,296,\n",
      "2015-03-12--20 12,228,240,244,248,252,256,260,264,272,288,296,\n",
      "2015-03-12--22 4,44,56,68,76,88,100,108,120,128,140,148,160,172,180,184,192,196,204,212,224,232,236,244,252,256,260,272,280,288,\n",
      "2015-03-13--00 32,40,\n",
      "2015-03-13--04 4,24,192,256,\n",
      "2015-03-13--22 148,152,160,172,188,192,232,\n",
      "2015-03-14--00 168,172,180,192,216,\n",
      "2015-03-14--04 0,4,16,48,\n",
      "2015-03-14--20 72,84,104,108,120,124,156,168,196,208,\n",
      "2015-03-14--22 0,32,44,52,64,92,96,104,136,144,176,\n",
      "2015-03-15--00 240,252,292,\n",
      "2015-03-15--02 0,4,12,16,24,32,40,52,56,60,64,68,72,76,80,84,88,92,96,100,104,108,112,116,120,124,132,136,148,156,164,168,180,224,228,240,252,264,276,280,288,292,\n",
      "2015-03-15--04 24,36,48,56,64,68,72,80,88,100,104,112,116,124,128,136,140,148,152,156,160,172,176,184,192,196,220,224,232,240,244,248,252,260,268,272,276,280,296,\n",
      "2015-03-15--18 264,268,276,284,288,296,\n",
      "2015-03-15--20 24,32,36,44,48,56,64,68,76,88,100,108,112,120,124,128,132,144,152,156,164,168,172,176,196,212,216,224,236,244,248,256,264,268,276,284,288,296,\n",
      "2015-03-15--22 0,8,16,20,28,32,40,48,52,60,68,72,80,88,100,108,112,120,128,132,140,148,160,188,204,220,240,252,260,272,280,\n",
      "2015-03-16--00 52,\n",
      "2015-03-16--02 164,\n",
      "2015-03-16--04 136,\n",
      "2015-03-16--14 12,20,28,32,40,52,264,268,\n",
      "2015-03-16--16 248,\n",
      "2015-03-16--18 12,20,24,36,48,52,60,72,104,108,136,148,152,156,160,168,180,184,196,208,212,224,240,244,248,260,264,268,276,280,284,288,292,296,\n",
      "2015-03-16--20 8,16,20,28,32,40,44,56,96,112,116,132,160,172,200,212,236,292,296,\n",
      "2015-03-16--22 0,16,\n",
      "2015-03-17--00 8,32,248,256,268,276,288,296,\n",
      "2015-03-17--02 0,4,8,12,16,20,24,32,44,48,52,64,68,72,76,80,84,88,92,96,100,104,108,120,128,132,136,140,144,148,152,156,160,164,168,172,176,184,188,192,200,208,212,216,228,236,240,244,252,264,276,284,288,296,\n",
      "2015-03-17--04 12,16,24,28,32,36,88,156,160,164,168,172,180,184,192,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,268,276,280,284,288,296,\n",
      "2015-03-17--08 216,\n",
      "2015-03-17--10 220,\n",
      "2015-03-17--16 0,4,8,12,16,24,28,32,40,44,48,52,60,64,68,72,76,80,88,92,96,100,104,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,216,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,\n",
      "2015-03-17--18 12,72,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,208,212,216,228,236,252,260,264,268,272,280,284,292,296,\n",
      "2015-03-17--20 0,4,8,12,20,32,40,52,56,60,72,76,80,84,88,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,188,196,200,208,212,220,224,228,232,244,252,256,264,268,276,284,288,296,\n",
      "2015-03-17--22 8,36,40,72,104,132,244,296,\n",
      "2015-03-18--00 4,52,116,128,132,136,140,144,148,152,156,164,168,180,188,220,240,248,252,260,264,276,280,288,292,296,\n",
      "2015-03-18--02 4,8,12,16,28,36,40,44,48,52,56,60,76,80,84,88,92,96,100,104,108,112,120,124,128,136,140,144,152,156,160,164,172,176,188,192,196,208,216,220,228,236,248,268,288,292,\n",
      "2015-03-18--04 0,8,16,20,28,32,40,48,52,76,108,140,144,148,156,160,168,172,184,192,196,200,204,208,212,224,228,236,240,244,248,252,260,268,272,276,280,284,288,292,\n",
      "2015-03-18--06 100,124,188,232,\n",
      "2015-03-18--08 28,32,52,56,64,80,84,100,104,108,112,124,128,132,136,140,144,148,156,160,164,168,172,176,188,192,196,204,208,220,224,228,232,240,252,284,\n",
      "2015-03-18--10 12,64,116,120,172,\n",
      "2015-03-18--12 12,16,20,24,32,36,64,68,72,76,80,212,276,284,288,292,296,\n",
      "2015-03-18--16 128,144,172,180,200,\n",
      "2015-03-18--18 12,20,24,40,44,48,52,56,60,64,68,72,76,80,84,88,92,96,100,104,108,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,264,268,276,280,284,288,292,296,\n",
      "2015-03-18--20 148,160,164,168,172,176,180,184,192,196,200,204,212,220,224,228,232,240,244,248,252,256,260,268,276,\n",
      "2015-03-18--22 60,100,108,140,152,164,172,176,184,188,192,196,200,204,212,216,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,296,\n",
      "2015-03-19--00 0,4,12,20,28,32,36,56,64,68,76,88,112,168,188,232,\n",
      "2015-03-19--02 0,4,8,12,16,20,24,28,36,40,44,48,56,60,68,76,92,104,116,128,140,152,160,184,188,192,196,200,252,260,264,268,272,276,280,284,288,292,296,\n",
      "2015-03-19--04 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,80,84,88,92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,160,164,172,180,184,188,192,196,208,212,216,224,228,232,236,240,244,248,252,256,260,264,272,276,284,288,296,\n",
      "2015-03-19--06 208,240,244,248,276,280,292,296,\n",
      "2015-03-19--08 44,72,152,\n",
      "2015-03-19--12 212,\n",
      "2015-03-19--14 236,252,\n",
      "2015-03-19--16 276,\n",
      "2015-03-19--18 12,16,28,36,76,88,148,156,168,176,188,200,204,\n",
      "2015-03-19--20 4,12,16,20,24,32,36,44,48,56,\n",
      "2015-03-19--22 4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,84,88,92,96,100,104,112,120,128,132,152,164,172,248,280,\n",
      "2015-03-20--00 276,296,\n",
      "2015-03-20--10 144,\n",
      "2015-03-20--12 20,\n",
      "2015-03-20--20 64,256,268,\n",
      "2015-03-20--22 216,236,\n",
      "2015-03-21--04 168,\n",
      "2015-03-21--08 220,\n",
      "2015-03-21--20 216,\n",
      "2015-03-21--22 140,176,\n",
      "2015-03-22--00 156,\n",
      "2015-03-22--02 144,152,156,\n",
      "2015-03-22--10 220,\n",
      "2015-03-22--20 84,124,144,152,156,164,220,272,\n",
      "2015-03-23--16 120,140,144,\n",
      "2015-03-23--18 0,4,8,24,28,40,44,48,56,72,76,84,112,124,136,168,172,288,\n",
      "2015-03-23--20 12,80,84,88,92,96,100,104,116,236,276,\n",
      "2015-03-24--02 100,288,\n",
      "2015-03-24--04 268,280,\n",
      "2015-03-24--06 4,16,24,36,44,56,64,68,76,84,104,256,\n",
      "2015-03-24--12 36,44,52,56,64,68,76,80,84,88,96,100,108,112,116,120,132,152,184,212,\n",
      "2015-03-24--16 92,\n",
      "2015-03-24--18 8,16,20,28,40,48,60,196,280,288,\n",
      "2015-03-24--20 16,28,196,216,224,228,\n",
      "2015-03-25--00 4,8,16,24,32,36,44,48,52,56,64,68,72,76,80,84,92,96,100,104,108,112,116,120,124,128,132,136,140,144,152,160,172,180,188,196,200,204,208,216,220,228,236,248,260,268,276,280,288,292,\n",
      "2015-03-25--02 8,16,24,48,56,68,252,\n",
      "2015-03-25--04 0,4,8,12,16,20,24,28,32,36,40,48,56,68,76,80,88,100,116,128,132,140,160,172,180,192,200,212,220,232,244,256,260,272,280,292,\n",
      "2015-03-25--06 188,200,212,220,232,236,276,292,\n",
      "2015-03-25--08 4,8,12,20,24,28,36,40,44,48,52,56,116,128,148,176,188,216,252,256,264,272,276,284,288,292,296,\n",
      "2015-03-25--12 192,\n",
      "2015-03-25--14 208,220,228,240,248,\n",
      "2015-03-25--16 108,292,\n",
      "2015-03-25--18 48,60,72,76,80,92,96,104,112,116,124,136,148,156,168,\n",
      "2015-03-25--20 4,8,12,16,24,36,44,48,56,60,64,76,80,88,100,108,120,132,140,152,164,176,184,188,196,208,220,224,228,232,240,244,252,264,276,284,\n",
      "2015-03-25--22 212,224,\n",
      "2015-03-26--00 64,84,92,120,128,204,272,280,\n",
      "2015-03-26--04 4,12,32,40,76,84,124,\n",
      "2015-03-26--06 48,80,92,104,112,116,124,156,212,232,244,292,\n",
      "2015-03-26--12 36,44,48,52,56,64,76,84,92,104,112,176,\n",
      "2015-03-26--16 184,192,196,204,264,276,288,\n",
      "2015-03-26--18 0,8,20,28,44,56,100,156,164,168,176,188,204,224,268,\n",
      "2015-03-26--20 4,16,24,28,36,44,48,56,76,84,88,96,104,116,124,132,144,152,172,180,192,200,208,220,228,236,248,256,276,284,292,\n",
      "2015-03-26--22 152,164,172,180,184,192,196,204,208,216,220,228,232,240,248,252,260,268,272,\n",
      "2015-03-27--02 40,52,88,96,104,116,124,136,144,156,164,184,192,200,212,220,228,256,284,292,\n",
      "2015-03-27--20 272,\n",
      "2015-03-28--00 112,136,180,\n",
      "2015-03-28--08 44,296,\n",
      "2015-03-29--00 0,4,8,12,20,24,28,32,36,40,44,52,56,60,64,68,72,76,80,84,88,92,96,100,104,108,112,116,120,124,128,136,140,144,148,152,156,168,172,176,184,188,192,196,200,204,212,216,220,224,232,240,244,252,260,264,272,280,284,288,292,\n",
      "2015-03-29--02 188,200,\n",
      "2015-03-29--04 24,200,\n",
      "2015-03-29--10 120,136,144,156,184,188,196,220,\n",
      "2015-03-29--12 152,156,160,\n",
      "2015-03-29--22 0,4,16,28,32,36,84,104,112,128,132,136,140,144,152,156,160,164,172,176,184,188,196,200,208,220,224,228,240,244,248,252,260,264,268,272,276,280,288,292,\n",
      "2015-03-30--02 60,100,120,\n",
      "2015-03-30--04 0,4,8,12,20,24,32,36,44,48,52,56,68,72,76,84,88,96,108,116,128,136,144,148,156,164,172,176,184,204,216,240,248,260,268,272,276,288,296,\n",
      "2015-03-30--06 12,40,48,56,\n",
      "2015-03-30--08 0,8,16,20,32,100,188,200,\n",
      "2015-03-30--10 284,\n",
      "2015-03-30--12 0,\n",
      "2015-03-30--14 148,160,168,172,180,184,192,196,200,204,212,216,220,224,\n",
      "2015-03-30--16 4,56,120,\n",
      "2015-03-30--18 124,136,144,152,156,164,168,172,176,180,188,200,208,\n",
      "2015-03-30--20 0,8,16,20,24,28,32,36,40,56,60,64,84,120,148,164,176,188,204,208,220,252,268,276,280,288,\n",
      "2015-03-30--22 4,12,16,20,24,28,32,40,60,72,80,84,92,96,100,104,112,120,132,140,144,152,160,168,180,188,196,204,208,212,216,224,232,240,244,252,256,260,264,268,272,276,280,284,292,296,\n",
      "2015-03-31--00 24,36,44,48,56,68,76,84,104,108,116,120,228,\n",
      "2015-03-31--02 232,\n",
      "2015-03-31--04 20,28,184,\n",
      "2015-03-31--06 244,256,260,268,272,280,284,292,\n",
      "2015-03-31--08 36,48,56,68,96,100,124,156,180,188,228,\n",
      "2015-03-31--10 12,16,32,44,52,60,68,72,80,92,100,104,112,120,132,140,152,156,164,168,172,176,184,188,192,196,204,208,212,216,224,228,232,236,244,252,264,268,272,276,280,284,288,292,296,\n",
      "2015-03-31--12 20,24,32,36,40,44,56,68,92,100,112,124,128,132,144,156,160,260,272,\n",
      "2015-03-31--16 4,\n",
      "2015-03-31--18 8,20,28,40,88,\n",
      "2015-03-31--20 96,288,\n",
      "2015-03-31--22 8,136,148,\n",
      "2015-04-01--00 44,208,216,224,228,236,244,256,268,272,\n",
      "2015-04-01--02 132,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-04-01--04 0,20,32,92,132,144,172,184,192,196,204,212,216,224,236,244,248,288,\n",
      "2015-04-01--08 72,164,232,\n",
      "2015-04-01--10 60,92,100,292,\n",
      "2015-04-01--12 48,52,172,\n",
      "2015-04-01--16 288,292,\n",
      "2015-04-01--20 236,268,\n",
      "2015-04-01--22 96,116,208,\n",
      "2015-04-02--08 256,264,268,276,280,288,\n",
      "2015-04-02--14 76,124,136,164,\n",
      "2015-04-02--18 4,8,16,20,28,36,48,56,76,84,96,124,144,152,164,172,192,200,212,220,224,232,240,260,\n",
      "2015-04-02--20 156,164,184,188,196,200,212,224,232,244,252,256,264,276,288,\n",
      "2015-04-03--00 24,48,60,96,176,\n",
      "2015-04-03--02 0,12,24,36,48,60,84,96,108,120,140,152,196,232,244,256,264,288,\n",
      "2015-04-03--04 84,220,240,\n",
      "2015-04-03--06 96,200,228,256,268,276,284,296,\n",
      "2015-04-03--08 0,4,8,12,16,20,24,28,32,36,40,44,52,56,60,64,72,76,84,96,100,116,120,140,152,160,196,204,280,296,\n",
      "2015-04-03--10 8,16,20,24,28,32,40,44,48,52,56,60,64,72,76,80,84,88,92,96,100,104,108,112,116,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,224,232,236,244,252,256,260,268,272,276,280,284,292,296,\n",
      "2015-04-03--12 0,8,16,20,28,32,40,52,64,72,92,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,\n",
      "2015-04-03--14 0,4,8,12,16,20,24,28,32,36,40,48,52,60,64,68,72,76,80,84,88,92,100,108,112,124,132,144,152,172,176,184,188,196,204,208,212,216,224,228,236,240,244,248,272,284,\n",
      "2015-04-03--16 8,20,28,40,52,60,64,72,76,84,88,96,100,104,108,116,128,136,140,148,160,164,168,172,180,184,188,196,200,204,208,220,228,236,244,256,276,288,296,\n",
      "2015-04-03--18 12,16,20,28,32,40,52,60,64,72,84,104,\n",
      "2015-04-03--20 4,16,20,24,32,36,40,44,48,56,64,68,72,76,80,84,88,92,100,104,112,116,124,132,136,140,144,152,156,160,164,172,176,180,184,192,196,200,204,208,212,216,220,224,232,240,244,248,252,256,264,268,272,276,280,284,288,292,296,\n",
      "2015-04-03--22 0,4,8,12,16,20,24,32,36,40,44,52,56,60,64,72,80,84,92,100,104,108,112,116,120,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,192,196,200,204,212,216,224,228,232,236,240,244,248,256,260,264,268,276,280,284,288,296,\n",
      "2015-04-04--00 0,4,8,12,16,24,28,36,40,44,56,60,64,68,76,124,128,132,144,148,152,156,168,196,200,212,216,224,228,236,248,280,292,\n",
      "2015-04-04--02 132,172,180,192,200,204,212,\n",
      "2015-04-04--04 284,\n",
      "2015-04-04--06 16,148,248,284,296,\n",
      "2015-04-04--08 20,28,40,52,80,84,120,280,292,\n",
      "2015-04-04--10 4,12,16,24,28,32,40,44,52,64,72,76,80,84,88,92,100,104,144,148,156,164,168,192,200,204,212,216,224,228,248,260,264,268,272,276,280,284,288,296,\n",
      "2015-04-04--12 92,\n",
      "2015-04-04--14 184,188,192,196,200,204,208,216,228,248,260,268,272,280,288,292,\n",
      "2015-04-04--16 12,16,60,68,84,\n",
      "2015-04-04--18 0,4,12,24,36,40,48,60,68,72,296,\n",
      "2015-04-04--20 184,192,244,\n",
      "2015-04-04--22 124,132,144,152,164,252,\n",
      "2015-04-05--02 104,144,164,176,180,184,188,192,196,200,204,208,212,216,220,224,228,232,240,248,252,260,264,272,284,296,\n",
      "2015-04-05--04 4,8,24,\n",
      "2015-04-05--10 224,\n",
      "2015-04-05--22 40,\n",
      "2015-04-06--00 280,\n",
      "2015-04-06--02 172,280,\n",
      "2015-04-06--12 120,132,180,\n",
      "2015-04-06--18 280,\n",
      "2015-04-07--10 68,72,92,140,176,200,236,\n",
      "2015-04-07--12 76,148,160,164,168,176,180,188,192,200,204,212,220,232,240,244,252,260,272,292,\n",
      "2015-04-07--14 0,4,8,16,20,24,28,32,36,40,48,52,60,64,68,72,80,84,88,92,100,104,112,120,124,132,136,144,148,152,156,164,168,176,180,184,188,196,200,208,216,228,\n",
      "2015-04-07--16 4,12,16,20,24,32,36,40,44,52,56,64,68,72,76,84,88,92,96,104,108,116,120,124,128,140,148,160,164,172,180,184,192,200,204,212,216,220,224,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,\n",
      "2015-04-07--20 136,\n",
      "2015-04-08--04 0,4,8,12,16,20,24,28,32,36,40,44,48,52,60,68,72,84,88,92,96,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,\n",
      "2015-04-08--06 48,\n",
      "2015-04-08--10 20,36,\n",
      "2015-04-08--12 172,176,268,276,\n",
      "2015-04-08--14 28,44,72,208,228,240,248,252,296,\n",
      "2015-04-08--16 16,20,72,100,176,192,196,260,268,\n",
      "2015-04-08--18 52,232,\n",
      "2015-04-08--20 0,4,12,16,24,28,36,40,44,52,56,72,96,124,136,140,144,156,164,172,176,184,192,196,204,208,212,216,220,224,228,232,236,240,248,252,256,260,268,272,276,280,284,288,296,\n",
      "2015-04-08--22 0,4,8,16,20,24,28,36,40,44,48,56,60,64,68,72,76,92,100,104,108,112,120,128,132,136,140,144,148,156,164,168,172,176,180,184,192,196,204,212,220,224,228,240,248,252,256,268,276,284,296,\n",
      "2015-04-09--00 4,12,20,24,28,40,48,56,72,76,84,88,92,96,100,104,112,116,120,124,132,140,144,148,152,160,164,208,260,268,272,\n",
      "2015-04-09--02 0,4,8,12,16,24,28,36,40,44,48,56,60,64,68,72,76,80,84,92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,212,216,220,224,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,\n",
      "2015-04-09--04 148,276,\n",
      "2015-04-09--08 280,284,\n",
      "2015-04-09--14 12,52,72,84,108,116,120,128,136,140,148,152,160,172,256,264,268,284,288,296,\n",
      "2015-04-09--16 24,32,40,44,52,56,60,64,72,76,80,84,92,100,104,108,112,120,124,128,136,140,148,156,164,168,176,180,184,192,216,228,256,264,272,276,280,284,292,\n",
      "2015-04-09--18 0,8,12,20,24,28,32,36,40,44,48,52,60,64,68,72,80,84,88,92,96,100,108,116,124,128,136,140,144,148,152,156,172,176,180,192,212,232,240,280,292,\n",
      "2015-04-09--20 56,64,68,72,80,84,92,96,104,108,112,116,124,128,136,140,144,148,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,\n",
      "2015-04-09--22 148,\n",
      "2015-04-10--02 32,56,68,80,116,128,136,152,164,\n",
      "2015-04-10--06 220,\n",
      "2015-04-10--10 80,\n",
      "2015-04-10--16 236,\n",
      "2015-04-10--18 72,104,116,128,136,148,152,164,184,\n",
      "2015-04-10--20 172,284,296,\n",
      "2015-04-10--22 152,\n",
      "2015-04-11--00 20,32,52,64,76,84,96,108,116,128,140,144,148,152,160,164,172,184,192,196,204,208,216,228,232,240,244,252,256,260,272,276,284,292,\n",
      "2015-04-11--04 148,204,224,228,236,240,248,260,268,272,280,292,\n",
      "2015-04-11--06 68,268,\n",
      "2015-04-11--08 268,\n",
      "2015-04-11--14 0,12,16,20,24,32,36,44,48,56,68,76,88,92,108,116,128,136,148,152,160,164,168,172,188,196,200,212,216,220,224,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,\n",
      "2015-04-11--16 28,40,52,56,64,76,84,88,92,96,100,108,112,116,120,128,132,136,140,144,148,152,160,164,168,172,180,184,188,192,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,\n",
      "2015-04-11--18 4,12,20,24,28,32,36,44,48,52,56,60,64,68,72,76,80,88,96,100,104,108,112,116,120,124,128,132,136,140,148,152,156,160,164,168,172,180,184,188,192,196,200,204,208,212,216,220,224,228,232,236,240,244,252,260,272,284,\n",
      "2015-04-11--20 44,56,68,76,88,92,100,112,116,120,124,128,132,140,144,176,180,200,212,216,220,224,232,236,260,264,272,276,296,\n",
      "2015-04-11--22 124,132,136,144,156,164,168,176,180,188,192,200,212,220,232,240,248,256,276,288,\n",
      "2015-04-12--00 0,20,24,32,36,40,44,52,56,68,76,80,88,92,100,112,260,264,272,296,\n",
      "2015-04-13--00 76,192,200,204,212,220,228,248,256,264,268,276,280,284,288,292,\n",
      "2015-04-13--02 4,12,24,32,44,52,60,80,92,112,132,144,152,160,168,172,180,188,200,208,220,228,232,240,248,252,260,268,276,280,288,296,\n",
      "2015-04-13--04 32,76,116,156,164,220,224,232,240,252,260,\n",
      "2015-04-13--06 72,\n",
      "2015-04-13--10 16,\n",
      "2015-04-13--12 224,\n",
      "2015-04-13--14 216,\n",
      "2015-04-13--16 92,116,120,140,160,164,172,176,196,204,208,220,232,240,244,252,256,264,272,276,284,288,296,\n",
      "2015-04-13--18 0,8,12,16,20,28,36,40,56,60,76,88,176,236,240,248,252,256,260,268,272,276,280,288,292,\n",
      "2015-04-13--20 4,8,44,48,64,84,92,96,104,112,116,148,152,168,176,188,200,212,244,252,284,\n",
      "2015-04-13--22 0,4,8,12,20,24,28,32,36,40,44,52,56,64,72,76,80,84,88,96,104,108,116,124,136,144,148,156,164,176,180,184,188,196,204,208,212,216,220,224,228,232,236,240,248,252,272,292,\n",
      "2015-04-14--00 4,16,20,24,36,40,44,56,60,64,68,72,76,84,88,92,100,104,108,112,116,120,124,132,136,140,144,148,152,156,164,168,172,176,180,184,196,200,204,208,212,216,220,224,228,232,236,244,248,256,260,268,280,288,292,\n",
      "2015-04-14--04 4,8,12,16,24,28,36,40,48,56,60,68,72,76,80,84,88,92,96,100,104,108,120,124,128,140,144,148,160,168,188,192,200,256,\n",
      "2015-04-14--14 168,\n",
      "2015-04-14--20 4,8,16,20,144,156,168,180,184,\n",
      "2015-04-15--20 0,72,\n",
      "2015-04-16--06 0,236,\n",
      "2015-04-16--18 84,88,112,120,124,132,144,156,160,168,172,192,196,200,204,212,220,\n",
      "2015-04-16--22 0,212,216,224,236,288,\n",
      "2015-04-17--14 96,112,152,180,196,256,260,264,268,280,284,292,296,\n",
      "2015-04-17--16 0,8,12,20,24,32,44,56,64,68,76,80,88,92,100,108,112,120,124,132,136,140,144,148,152,156,168,176,188,200,212,220,224,232,244,252,\n",
      "2015-04-19--22 132,\n",
      "2015-04-20--08 128,132,136,144,148,152,156,\n",
      "2015-04-20--10 20,56,80,\n",
      "2015-04-20--12 192,196,212,224,232,\n",
      "2015-04-20--16 0,8,12,20,24,36,48,80,84,92,104,108,124,132,136,144,148,156,160,168,176,184,188,196,200,208,216,224,228,236,240,244,248,252,256,264,268,276,280,284,292,296,\n",
      "2015-04-20--18 4,52,68,72,76,80,88,92,104,116,124,132,136,140,144,148,160,176,184,196,208,212,220,232,244,248,256,280,296,\n",
      "2015-04-21--10 0,\n",
      "2015-04-21--16 32,44,\n",
      "2015-04-21--18 32,228,\n",
      "2015-04-21--20 0,12,16,20,80,88,112,124,136,156,160,172,196,208,216,220,228,232,236,244,248,268,\n",
      "2015-04-21--22 28,40,64,76,88,124,136,148,296,\n",
      "2015-04-22--00 28,32,40,44,52,60,64,72,76,84,96,104,108,116,120,128,132,140,144,148,160,168,180,240,\n",
      "2015-04-22--02 292,\n",
      "2015-04-23--02 44,\n",
      "2015-04-23--04 100,112,\n",
      "2015-04-23--08 0,\n",
      "2015-04-23--18 116,132,144,\n",
      "2015-04-23--20 0,4,12,16,24,\n",
      "2015-04-23--22 32,44,48,56,60,72,96,232,236,\n",
      "2015-04-24--00 104,140,224,236,244,248,\n",
      "2015-04-24--04 252,\n",
      "2015-04-24--16 24,36,48,60,72,84,92,104,292,\n",
      "2015-04-25--00 32,44,64,68,76,80,88,188,208,212,240,252,264,296,\n",
      "2015-04-25--16 276,\n",
      "2015-04-26--08 0,4,12,16,24,36,44,48,56,60,64,68,72,80,84,92,96,104,116,128,132,136,140,144,\n",
      "2015-04-26--10 196,260,272,284,\n",
      "2015-04-27--00 64,\n",
      "2015-04-27--06 8,16,20,28,40,56,64,84,96,108,120,132,136,140,152,164,176,184,188,192,196,204,208,220,232,244,268,272,276,280,284,288,296,\n",
      "2015-04-27--08 0,12,32,44,56,88,100,108,112,120,124,132,136,140,148,168,180,204,208,216,228,240,244,256,264,268,272,276,280,288,292,\n",
      "2015-04-27--18 200,208,212,224,236,248,260,\n",
      "2015-04-30--06 0,12,16,24,32,36,44,48,56,80,92,104,116,128,168,208,228,232,256,268,272,\n",
      "2015-05-01--06 0,36,56,192,\n",
      "2015-05-02--10 4,16,24,32,56,64,96,116,124,144,152,156,164,172,184,192,212,232,240,244,252,260,272,280,292,\n",
      "2015-05-02--12 16,44,52,80,\n",
      "2015-05-02--14 208,220,256,260,272,284,\n",
      "2015-05-02--18 0,\n",
      "2015-05-02--20 232,240,244,248,256,268,\n",
      "2015-05-03--02 148,\n",
      "2015-05-03--04 152,232,236,240,264,276,280,284,288,\n",
      "2015-05-03--06 200,\n",
      "2015-05-03--08 76,80,84,92,188,\n",
      "2015-05-03--10 176,180,192,204,216,\n",
      "2015-05-03--12 52,56,64,68,80,92,104,108,116,120,132,144,156,160,180,184,192,196,204,208,216,220,232,244,248,256,260,268,272,284,\n",
      "2015-05-03--14 12,68,72,76,84,88,96,100,108,120,128,132,140,144,152,156,164,168,176,180,188,192,200,212,216,220,224,228,232,236,240,\n",
      "2015-05-03--16 0,4,8,16,20,28,32,40,44,52,64,76,80,88,92,100,108,112,116,160,184,196,208,220,248,256,\n",
      "2015-05-03--18 8,16,24,28,32,72,92,112,148,260,264,276,288,292,\n",
      "2015-05-03--20 4,44,56,68,80,96,100,112,124,136,140,148,152,164,176,180,192,204,208,216,220,232,236,244,248,256,260,\n",
      "2015-05-03--22 0,4,8,12,16,24,28,36,40,44,48,52,60,72,76,80,84,88,92,96,100,104,108,112,116,120,124,128,132,136,140,144,156,168,172,176,188,192,200,204,216,228,240,\n",
      "2015-05-04--00 20,32,44,104,236,248,260,264,272,276,288,\n",
      "2015-05-04--02 200,216,224,228,240,244,252,256,264,276,\n",
      "2015-05-04--06 144,\n",
      "2015-05-04--08 0,24,72,84,96,152,\n",
      "2015-05-04--10 152,160,184,216,232,240,244,252,256,264,268,272,276,280,288,292,\n",
      "2015-05-04--14 256,268,276,288,\n",
      "2015-05-04--16 84,88,100,212,216,224,228,236,240,248,252,260,264,276,288,292,\n",
      "2015-05-04--22 180,192,196,204,208,212,220,232,244,256,260,268,272,280,284,292,296,\n",
      "2015-05-05--00 4,8,16,20,28,32,40,44,56,200,212,284,\n",
      "2015-05-05--06 4,44,56,248,260,288,\n",
      "2015-05-05--08 4,28,48,72,76,96,120,132,144,156,180,192,204,224,236,240,252,264,280,292,\n",
      "2015-05-05--10 148,168,180,248,264,276,288,292,\n",
      "2015-05-05--12 0,8,20,24,32,36,44,48,60,72,76,84,88,104,156,172,184,188,204,212,220,224,232,244,264,276,284,296,\n",
      "2015-05-05--14 0,4,8,12,36,208,220,224,\n",
      "2015-05-05--22 4,20,\n",
      "2015-05-06--00 12,44,60,136,152,160,164,\n",
      "2015-05-06--06 76,\n",
      "2015-05-07--16 20,44,212,228,236,240,248,252,264,276,288,\n",
      "2015-05-08--16 288,\n",
      "2015-05-09--16 236,268,\n",
      "2015-05-10--10 92,108,\n",
      "2015-05-10--16 0,12,20,24,28,32,36,40,44,48,52,60,64,104,108,128,140,144,180,184,192,204,216,268,272,\n",
      "2015-05-10--20 188,200,204,212,216,228,240,252,256,264,276,288,292,\n",
      "2015-05-10--22 52,56,64,92,104,116,120,128,140,144,152,156,168,180,192,204,208,216,220,\n",
      "2015-05-11--00 108,120,128,132,140,144,152,156,204,240,\n",
      "2015-05-11--02 0,8,20,32,44,260,\n",
      "2015-05-11--04 160,\n",
      "2015-05-11--22 192,\n",
      "2015-05-12--00 4,\n",
      "2015-05-12--02 128,152,160,\n",
      "2015-05-12--04 192,\n",
      "2015-05-12--14 272,284,296,\n",
      "2015-05-12--16 108,112,124,152,164,172,\n",
      "2015-05-13--00 44,160,\n",
      "2015-05-13--14 204,228,284,\n",
      "2015-05-13--16 0,12,16,40,44,52,68,76,80,88,92,104,116,128,132,140,144,152,156,160,168,180,184,192,196,208,220,224,\n",
      "2015-05-15--08 188,\n",
      "2015-05-15--18 60,\n",
      "2015-05-15--22 0,16,28,56,76,\n",
      "2015-05-20--00 116,236,276,\n",
      "2015-05-21--16 60,\n",
      "2015-05-22--06 68,72,76,\n",
      "2015-05-23--10 140,176,184,\n",
      "2015-05-26--06 0,4,12,16,24,36,48,60,72,80,84,96,108,120,132,140,144,152,164,168,176,180,184,192,196,208,212,216,220,224,228,232,240,\n",
      "2015-05-27--16 104,108,112,116,124,\n",
      "2015-05-31--08 36,48,52,56,60,64,68,76,80,84,104,124,132,148,208,240,\n",
      "2015-05-31--10 0,8,12,16,20,24,28,32,40,44,48,52,56,64,68,72,76,80,84,88,92,96,100,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,208,212,216,220,224,228,232,236,240,244,248,252,256,260,264,268,276,280,284,288,292,296,\n",
      "2015-06-07--10 296,\n",
      "2015-06-11--00 84,\n",
      "2015-06-11--18 256,\n",
      "2015-06-12--20 108,\n",
      "2015-06-16--06 12,40,116,\n",
      "2015-06-16--10 180,208,\n",
      "2015-06-16--18 288,\n",
      "2015-06-17--06 276,288,\n",
      "2015-06-18--14 28,\n",
      "2015-06-18--20 132,140,280,\n",
      "2015-06-19--04 8,12,32,40,52,60,80,100,124,176,208,220,228,232,256,268,272,292,\n",
      "2015-06-19--10 184,\n",
      "2015-06-20--20 12,52,64,80,108,\n",
      "2015-06-25--22 84,\n",
      "2015-07-08--20 16,\n",
      "2015-07-14--00 60,\n",
      "2015-07-14--08 20,24,28,44,48,52,56,64,72,76,80,84,88,92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,224,232,236,240,252,256,260,264,268,272,276,280,284,292,\n",
      "2015-07-15--04 276,\n",
      "2015-07-16--10 196,\n",
      "2015-07-19--06 28,44,76,80,184,200,280,\n",
      "2015-07-19--08 28,\n",
      "2015-07-19--10 0,144,148,152,176,196,216,248,284,\n",
      "2015-07-19--14 276,280,284,\n",
      "2015-07-19--16 132,228,248,\n",
      "2015-07-19--18 52,168,176,180,224,228,240,\n",
      "2015-07-19--22 36,40,52,56,72,88,92,124,128,172,180,196,200,228,264,\n",
      "2015-07-20--00 52,56,\n",
      "2015-07-20--10 64,200,204,208,\n",
      "2015-07-20--12 0,36,44,48,80,84,112,120,152,168,180,184,192,216,224,228,232,236,244,248,264,\n",
      "2015-07-20--14 104,152,252,284,288,\n",
      "2015-07-20--16 4,52,60,64,68,72,80,140,144,160,184,188,212,248,264,272,280,288,\n",
      "2015-07-20--18 0,24,48,72,84,144,160,228,236,240,264,276,\n",
      "2015-07-20--20 132,184,196,240,244,288,\n",
      "2015-07-21--00 8,12,40,44,60,68,80,124,144,152,156,176,184,188,208,212,220,240,268,280,284,\n",
      "2015-07-21--02 264,\n",
      "2015-07-21--04 12,16,20,24,28,32,72,76,84,92,104,112,120,124,148,152,160,184,192,196,224,232,260,\n",
      "2015-07-21--06 0,24,60,64,104,116,140,144,156,176,272,\n",
      "2015-07-21--10 0,4,20,48,76,100,164,196,200,204,236,244,252,272,276,\n",
      "2015-07-21--12 4,48,84,172,176,180,224,232,236,240,244,252,280,284,292,\n",
      "2015-07-21--14 16,56,60,284,\n",
      "2015-07-21--20 32,40,56,88,96,104,120,168,\n",
      "2015-07-21--22 16,44,52,56,60,140,180,184,280,\n",
      "2015-07-22--00 16,116,124,168,176,204,208,\n",
      "2015-07-22--14 176,\n",
      "2015-07-23--20 88,\n",
      "2015-07-24--00 140,\n",
      "2015-07-24--02 72,232,236,252,\n",
      "2015-08-04--12 144,188,268,276,\n",
      "2015-08-04--14 244,248,256,272,276,280,284,288,292,296,\n",
      "2015-08-05--06 280,\n",
      "2015-08-09--10 188,\n",
      "2015-08-12--10 0,4,8,12,16,20,24,28,32,36,40,44,48,56,60,68,72,76,80,84,88,92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,224,228,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,\n",
      "2015-08-13--22 196,\n",
      "2015-08-14--12 180,\n",
      "2015-08-14--20 24,44,112,144,180,220,252,268,280,284,288,292,\n",
      "2015-08-17--10 196,216,220,224,236,244,276,\n",
      "2015-08-20--10 136,\n",
      "2015-08-21--04 12,16,20,\n",
      "2015-08-21--06 76,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-09-13--22 24,\n",
      "2015-09-17--12 4,8,16,92,100,104,184,188,200,260,268,\n",
      "2015-09-17--14 48,124,172,\n",
      "2015-09-17--16 12,236,240,244,248,264,\n",
      "2015-09-17--18 80,84,176,180,248,252,\n",
      "2015-09-17--20 56,204,\n",
      "2015-09-17--22 52,80,108,112,116,264,\n",
      "2015-09-18--04 84,96,268,\n",
      "2015-09-18--06 0,108,144,248,264,276,\n",
      "2015-09-18--18 32,\n",
      "2015-09-19--04 180,\n",
      "2015-09-19--12 0,4,8,12,16,20,24,28,32,36,44,48,52,56,60,64,68,72,76,80,84,88,92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,216,224,\n",
      "2015-09-20--06 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,100,104,108,112,120,124,128,132,136,140,172,176,180,184,188,192,196,200,204,208,212,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,\n",
      "2015-09-20--08 0,4,8,12,16,20,24,28,32,36,40,44,48,56,60,64,68,72,80,84,88,92,100,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,\n",
      "2015-09-20--10 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,80,84,88,92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,\n",
      "2015-09-20--12 192,\n",
      "2015-09-20--22 92,124,132,140,\n",
      "2015-09-21--00 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,80,84,88,92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,\n",
      "2015-09-22--10 248,\n",
      "2015-09-23--14 12,52,60,64,68,80,92,100,104,116,136,140,144,148,152,156,160,164,168,172,176,260,\n",
      "2015-09-23--16 20,252,\n",
      "2015-09-23--22 8,12,16,228,232,236,\n",
      "2015-09-27--08 120,\n",
      "2015-09-28--04 0,8,12,20,32,36,40,48,52,56,72,116,136,156,160,164,176,180,184,188,192,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,260,264,268,272,280,284,288,292,\n",
      "2015-09-29--16 192,\n",
      "2015-09-30--10 0,8,12,16,20,28,32,36,48,52,56,60,68,72,76,80,84,88,96,104,108,112,116,120,124,136,144,148,160,164,188,196,204,212,216,220,224,244,252,256,260,268,288,292,\n",
      "2015-09-30--12 296,\n",
      "2015-10-13--10 24,36,40,44,52,80,84,96,104,108,116,120,160,164,176,188,192,196,204,208,216,220,224,228,232,236,252,260,264,276,296,\n",
      "2015-10-26--06 256,264,\n",
      "2015-11-01--22 276,\n",
      "2015-11-02--02 100,\n",
      "2015-11-02--04 132,\n",
      "2015-11-02--06 200,\n",
      "2015-11-04--06 220,236,240,244,\n",
      "2015-11-05--12 132,152,224,240,248,\n",
      "2015-11-13--02 84,216,\n",
      "2015-11-13--14 140,148,156,168,180,184,\n",
      "2015-11-13--16 140,200,232,\n",
      "2015-11-13--18 68,\n",
      "2015-11-13--22 148,\n",
      "2015-11-14--00 240,\n",
      "2015-11-14--04 260,\n",
      "2015-11-14--06 32,40,\n",
      "2015-11-14--10 44,\n",
      "2015-11-14--12 292,\n",
      "2015-11-14--18 156,\n",
      "2015-11-14--20 12,\n",
      "2015-11-15--00 152,\n",
      "2015-11-15--02 28,168,216,\n",
      "2015-11-15--04 288,\n",
      "2015-11-15--06 4,\n",
      "2015-11-15--08 72,216,\n",
      "2015-11-15--16 196,\n",
      "2015-11-15--18 168,184,\n",
      "2015-11-15--20 24,32,96,104,112,132,184,204,\n",
      "2015-11-19--14 208,236,\n",
      "2015-11-22--14 68,72,100,176,180,184,188,220,\n",
      "2015-11-23--04 160,\n",
      "2015-11-23--06 48,152,\n",
      "2015-11-23--08 112,\n",
      "2015-11-23--14 80,104,292,\n",
      "2015-11-24--00 40,\n",
      "2015-11-24--04 160,\n",
      "2015-11-24--06 72,\n",
      "2015-11-24--08 132,\n",
      "2015-11-28--12 104,\n",
      "2015-12-01--10 236,\n",
      "2015-12-04--04 40,48,52,60,68,\n",
      "2015-12-05--08 260,\n",
      "2015-12-06--02 80,\n",
      "2015-12-07--20 228,\n",
      "2015-12-09--18 288,\n",
      "2015-12-11--20 20,\n",
      "2015-12-12--06 48,116,196,\n",
      "2015-12-13--06 48,148,\n",
      "2015-12-14--16 84,124,\n",
      "2015-12-16--04 32,\n",
      "2015-12-16--08 112,168,184,192,220,248,264,\n",
      "2015-12-16--12 236,\n",
      "2015-12-17--16 132,164,\n",
      "2015-12-17--18 12,28,44,56,76,120,124,136,144,180,280,292,\n",
      "2015-12-17--20 28,64,88,112,132,188,196,204,232,240,264,272,\n",
      "2015-12-18--04 92,\n",
      "2015-12-18--18 4,8,16,80,88,100,120,124,128,132,140,144,152,160,172,\n",
      "2015-12-18--22 0,4,8,12,20,24,68,92,128,132,140,144,152,156,168,172,180,184,192,196,208,280,284,292,\n",
      "2015-12-19--00 4,8,20,32,40,52,56,60,68,72,84,88,92,104,116,120,128,132,136,144,148,160,172,176,180,192,196,200,204,208,216,224,228,232,236,240,244,252,260,264,284,\n",
      "2015-12-19--02 12,100,\n",
      "2015-12-19--20 8,16,36,44,56,64,88,92,96,104,116,120,124,128,132,136,140,144,148,152,160,172,180,\n",
      "2015-12-19--22 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,80,88,96,108,124,132,136,152,160,168,196,\n",
      "2015-12-20--00 0,8,12,20,24,28,32,36,44,52,56,64,68,72,76,80,84,92,100,108,112,116,120,128,132,136,140,144,148,152,156,164,168,172,176,180,184,192,196,200,204,208,212,216,220,224,228,232,240,244,248,252,256,260,268,272,276,280,284,288,296,\n",
      "2015-12-20--02 8,56,68,72,76,80,88,96,100,108,112,116,120,124,128,132,136,144,148,152,156,160,168,172,176,180,188,192,196,200,204,212,216,224,228,232,236,240,244,248,252,260,264,268,272,276,280,284,288,\n",
      "2015-12-20--06 0,4,8,12,16,20,28,36,44,52,60,68,72,76,80,84,88,92,100,104,108,112,116,120,132,136,140,144,148,152,156,164,172,180,184,188,192,196,200,208,212,216,228,232,236,240,244,248,252,256,260,264,268,272,276,280,\n",
      "2015-12-20--10 0,8,12,68,104,112,120,132,136,164,168,\n",
      "2015-12-20--12 272,\n",
      "2015-12-20--18 92,120,212,216,220,236,\n",
      "2015-12-20--22 0,4,12,20,28,40,48,52,180,192,200,252,280,\n",
      "2015-12-21--00 16,20,28,36,\n",
      "2015-12-21--02 0,12,20,32,96,108,116,136,\n",
      "2015-12-21--04 4,12,24,276,288,\n",
      "2015-12-21--06 104,108,112,160,168,180,208,212,228,240,248,252,268,276,\n",
      "2015-12-22--00 48,\n",
      "2015-12-22--06 0,\n",
      "2015-12-22--18 148,212,\n",
      "2015-12-22--20 256,\n",
      "2015-12-23--02 32,\n",
      "2015-12-23--10 220,\n",
      "2015-12-23--16 0,20,24,28,32,72,76,84,116,128,148,152,188,240,\n",
      "2015-12-23--18 4,8,20,36,116,180,\n",
      "2015-12-23--20 40,56,60,64,72,76,80,84,88,92,96,100,108,112,116,120,124,128,132,140,144,148,152,156,164,168,180,184,204,208,220,228,240,264,268,280,292,\n",
      "2015-12-23--22 84,88,116,120,132,136,148,160,164,168,176,180,188,192,200,204,216,220,236,244,260,272,\n",
      "2015-12-24--02 0,4,8,16,20,24,32,36,40,48,52,60,64,72,76,80,84,88,96,100,112,116,120,128,132,136,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,228,240,244,252,256,264,268,280,284,292,296,\n",
      "2015-12-24--04 4,32,76,184,\n",
      "2015-12-24--06 4,16,44,\n",
      "2015-12-24--08 192,220,240,244,260,272,276,288,292,\n",
      "2015-12-24--10 164,\n",
      "2015-12-24--12 16,28,40,52,64,76,88,96,100,160,184,196,212,224,228,236,240,\n",
      "2015-12-24--16 164,220,\n",
      "2015-12-24--20 4,16,28,40,68,80,92,104,116,128,156,160,168,180,196,216,232,248,264,284,\n",
      "2015-12-25--02 140,152,164,\n",
      "2015-12-25--04 140,184,188,196,220,232,236,244,248,256,260,272,284,\n",
      "2015-12-25--06 44,52,56,68,80,92,120,132,144,148,184,\n",
      "2015-12-25--08 4,20,36,40,52,64,68,80,92,96,108,120,136,148,188,200,236,\n",
      "2015-12-25--14 8,20,32,44,\n",
      "2015-12-25--22 64,\n",
      "2015-12-26--06 116,124,180,\n",
      "2015-12-26--22 284,\n",
      "2015-12-27--12 192,\n",
      "2015-12-28--08 156,\n",
      "2015-12-28--16 212,\n",
      "2015-12-29--00 156,\n",
      "2015-12-29--06 24,200,220,240,248,\n",
      "2015-12-29--08 28,68,76,124,128,132,208,228,\n",
      "2015-12-29--10 16,28,32,116,188,192,216,224,\n",
      "2015-12-29--14 0,136,148,164,176,272,288,\n",
      "2015-12-29--16 156,208,248,268,288,296,\n",
      "2015-12-29--18 24,96,108,168,172,264,292,296,\n",
      "2015-12-29--20 8,128,136,\n",
      "2015-12-29--22 236,288,\n",
      "2015-12-30--00 20,32,36,84,100,108,\n",
      "2015-12-31--08 208,264,272,\n",
      "2015-12-31--14 100,128,184,208,236,\n",
      "2015-12-31--16 0,24,40,60,72,84,96,100,172,184,188,200,212,240,244,"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import soundfile as sf\n",
    "\n",
    "# dir containing sound files\n",
    "srcdir = './data/every_other_hour'\n",
    "destdir = './data/model/detections/'\n",
    "\n",
    "df = read_clipnames(srcdir)\n",
    "\n",
    "print('Scanning recording:')\n",
    "# read and predict whale songs\n",
    "for i, (dt, path) in df.iterrows():\n",
    "    # load the recording audio, resample to clf's trained samprate\n",
    "    y, sr = librosa.load(path, sr=clf.samprate)\n",
    "    # predict whether any frames in this clip have whale song\n",
    "    pred = clf.predict_from_wave(y)\n",
    "    # save audio for any frames that model claims have whale song\n",
    "    first = True\n",
    "    for j,p in enumerate(pred):\n",
    "        if p > 0:\n",
    "            if first:\n",
    "                print()\n",
    "                print(os.path.basename(path).split('.')[0],end=' ')\n",
    "                first = False\n",
    "            print('%d,'%(j*clf.framesize/clf.samprate),end='')\n",
    "            sf.write('%s_%03d.wav'%(destdir+os.path.basename(path).split('.')[0],\n",
    "                    j*clf.framesize/clf.samprate), \n",
    "                    y[j*clf.framesize:(j+1)*clf.framesize], sr, subtype='PCM_16')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
